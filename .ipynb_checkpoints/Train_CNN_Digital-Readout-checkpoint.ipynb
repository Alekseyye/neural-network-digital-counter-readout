{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Target of this code is to train a CNN network to classify images of a digital readout to the digits 0 to 9. Additionally a category \"NaN\" is introduced, to mark images that are not amibiguous.\n",
    "\n",
    "### Preparing the training\n",
    "* First all libraries are loaded\n",
    "    * It is assumed, that they are installed during the Python setup\n",
    "* matplotlib is set to print the output inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "    \n",
    "TFliteNamingAndVersion = \"dig1000s0\"     # Used for tflite Filename\n",
    "Training_Percentage = 0.2              # 0.0 = Use all Images for Training\n",
    "Epoch_Anz = 500\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import History \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image \n",
    "\n",
    "loss_ges = np.array([])\n",
    "val_loss_ges = np.array([])\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Inside subdirectories are expected from -1, 0, 1, ... 9 in which the pictures are sorted according to their values (=category)\n",
    "* Picture size must be 20x32 with 3 color channels (RGB)\n",
    "* The filename can be arbitrary\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected category for each image in the corresponding y_data[]\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) and split the data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1064, 32, 20, 3)\n",
      "(1064, 11)\n"
     ]
    }
   ],
   "source": [
    "Input_dir='ziffer_sortiert_resize'\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.*')\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "subdir = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"NaN\"]\n",
    "\n",
    "for aktsubdir in subdir:\n",
    "    files = glob.glob(Input_dir + '/' + aktsubdir + '/*.jpg')\n",
    "    if aktsubdir == \"NaN\":\n",
    "        category = 10                # NaN does not work --> convert to 10\n",
    "    else:\n",
    "        category = aktsubdir\n",
    "    for aktfile in files:\n",
    "        test_image = Image.open(aktfile)\n",
    "        test_image = np.array(test_image, dtype=\"float32\")\n",
    "        x_data.append(test_image)\n",
    "        y_data.append(np.array([category]))\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "y_data = to_categorical(y_data, 11)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "else:\n",
    "    X_train = x_data\n",
    "    y_train = y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The layout of the network ist a typcial CNN network with alternating **Conv2D** and **MaxPool2D** layers. Finished after **flattening** with additional **Dense** layer.\n",
    "\n",
    "#### Important\n",
    "* Shape of the input layer: (32, 20, 3)\n",
    "* Number of output layers: 11\n",
    "* As loss function \"categorical_crossentropy\" is choosen, as it is a categories task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 32, 20, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 20, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                5643      \n",
      "=================================================================\n",
      "Total params: 324,631\n",
      "Trainable params: 324,625\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(32,20,3)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dense(11, activation = \"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The input pictures are randomly scattered for brightness, pixel shift variations and rotation angle. This is implemented with a ImageDataGenerator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "266/266 [==============================] - 17s 35ms/step - loss: 2.0928 - accuracy: 0.3833 - val_loss: 1.3632 - val_accuracy: 0.5587\n",
      "Epoch 2/500\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 1.2706 - accuracy: 0.5754 - val_loss: 1.0543 - val_accuracy: 0.6854\n",
      "Epoch 3/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.9249 - accuracy: 0.7237 - val_loss: 0.7141 - val_accuracy: 0.8122\n",
      "Epoch 4/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.7128 - accuracy: 0.7734 - val_loss: 0.5763 - val_accuracy: 0.8216\n",
      "Epoch 5/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.5978 - accuracy: 0.8244 - val_loss: 0.6611 - val_accuracy: 0.7887\n",
      "Epoch 6/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.5239 - accuracy: 0.8258 - val_loss: 0.4135 - val_accuracy: 0.8920\n",
      "Epoch 7/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.5424 - accuracy: 0.8173 - val_loss: 0.3632 - val_accuracy: 0.8732\n",
      "Epoch 8/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.4386 - accuracy: 0.8668 - val_loss: 0.3495 - val_accuracy: 0.8779\n",
      "Epoch 9/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.3825 - accuracy: 0.8738 - val_loss: 0.2910 - val_accuracy: 0.8873\n",
      "Epoch 10/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.3339 - accuracy: 0.8952 - val_loss: 0.2958 - val_accuracy: 0.8967\n",
      "Epoch 11/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.3096 - accuracy: 0.9079 - val_loss: 0.2063 - val_accuracy: 0.9249\n",
      "Epoch 12/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.3000 - accuracy: 0.9140 - val_loss: 0.2495 - val_accuracy: 0.9108\n",
      "Epoch 13/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.2843 - accuracy: 0.9240 - val_loss: 0.2526 - val_accuracy: 0.9343\n",
      "Epoch 14/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.2562 - accuracy: 0.9235 - val_loss: 0.2894 - val_accuracy: 0.9014\n",
      "Epoch 15/500\n",
      "266/266 [==============================] - 4s 13ms/step - loss: 0.2751 - accuracy: 0.9114 - val_loss: 0.2051 - val_accuracy: 0.9343\n",
      "Epoch 16/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.2339 - accuracy: 0.9343 - val_loss: 0.2129 - val_accuracy: 0.9249\n",
      "Epoch 17/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.2454 - accuracy: 0.9205 - val_loss: 0.2673 - val_accuracy: 0.9249\n",
      "Epoch 18/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.2415 - accuracy: 0.9317 - val_loss: 0.4305 - val_accuracy: 0.9108\n",
      "Epoch 19/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.2331 - accuracy: 0.9337 - val_loss: 0.1620 - val_accuracy: 0.9531\n",
      "Epoch 20/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.2113 - accuracy: 0.9398 - val_loss: 0.2100 - val_accuracy: 0.9343\n",
      "Epoch 21/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.2351 - accuracy: 0.9284 - val_loss: 0.1101 - val_accuracy: 0.9390\n",
      "Epoch 22/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1988 - accuracy: 0.9418 - val_loss: 0.1115 - val_accuracy: 0.9577\n",
      "Epoch 23/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.2089 - accuracy: 0.9357 - val_loss: 0.1536 - val_accuracy: 0.9437\n",
      "Epoch 24/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1440 - accuracy: 0.9671 - val_loss: 0.1444 - val_accuracy: 0.9390\n",
      "Epoch 25/500\n",
      "266/266 [==============================] - 3s 13ms/step - loss: 0.1680 - accuracy: 0.9571 - val_loss: 0.1106 - val_accuracy: 0.9718\n",
      "Epoch 26/500\n",
      "266/266 [==============================] - 4s 13ms/step - loss: 0.2162 - accuracy: 0.9274 - val_loss: 0.0725 - val_accuracy: 0.9765\n",
      "Epoch 27/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1920 - accuracy: 0.9418 - val_loss: 0.0967 - val_accuracy: 0.9718\n",
      "Epoch 28/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1275 - accuracy: 0.9663 - val_loss: 0.1007 - val_accuracy: 0.9624\n",
      "Epoch 29/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1217 - accuracy: 0.9617 - val_loss: 0.2295 - val_accuracy: 0.9343\n",
      "Epoch 30/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0914 - accuracy: 0.9621 - val_loss: 0.2256 - val_accuracy: 0.9437\n",
      "Epoch 31/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1067 - accuracy: 0.9694 - val_loss: 0.0716 - val_accuracy: 0.9671\n",
      "Epoch 32/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1180 - accuracy: 0.9501 - val_loss: 0.1638 - val_accuracy: 0.9577\n",
      "Epoch 33/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1480 - accuracy: 0.9683 - val_loss: 0.2603 - val_accuracy: 0.9531\n",
      "Epoch 34/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1711 - accuracy: 0.9600 - val_loss: 0.1716 - val_accuracy: 0.9390\n",
      "Epoch 35/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1415 - accuracy: 0.9564 - val_loss: 0.1440 - val_accuracy: 0.9577\n",
      "Epoch 36/500\n",
      "266/266 [==============================] - 4s 13ms/step - loss: 0.1559 - accuracy: 0.9587 - val_loss: 0.1427 - val_accuracy: 0.9577\n",
      "Epoch 37/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1378 - accuracy: 0.9584 - val_loss: 0.1207 - val_accuracy: 0.9624\n",
      "Epoch 38/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1765 - accuracy: 0.9495 - val_loss: 0.1376 - val_accuracy: 0.9671\n",
      "Epoch 39/500\n",
      "266/266 [==============================] - 4s 13ms/step - loss: 0.1051 - accuracy: 0.9687 - val_loss: 0.1728 - val_accuracy: 0.9624\n",
      "Epoch 40/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1197 - accuracy: 0.9631 - val_loss: 0.1995 - val_accuracy: 0.9577\n",
      "Epoch 41/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1440 - accuracy: 0.9580 - val_loss: 0.1286 - val_accuracy: 0.9671\n",
      "Epoch 42/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1042 - accuracy: 0.9661 - val_loss: 0.0928 - val_accuracy: 0.9718\n",
      "Epoch 43/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1367 - accuracy: 0.9666 - val_loss: 0.0728 - val_accuracy: 0.9765\n",
      "Epoch 44/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0604 - accuracy: 0.9856 - val_loss: 0.1635 - val_accuracy: 0.9718\n",
      "Epoch 45/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0926 - accuracy: 0.9738 - val_loss: 0.0302 - val_accuracy: 0.9906\n",
      "Epoch 46/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1250 - accuracy: 0.9667 - val_loss: 0.1101 - val_accuracy: 0.9624\n",
      "Epoch 47/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0809 - accuracy: 0.9747 - val_loss: 0.0516 - val_accuracy: 0.9671\n",
      "Epoch 48/500\n",
      "266/266 [==============================] - 4s 13ms/step - loss: 0.1170 - accuracy: 0.9635 - val_loss: 0.0701 - val_accuracy: 0.9765\n",
      "Epoch 49/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1399 - accuracy: 0.9586 - val_loss: 0.0541 - val_accuracy: 0.9765\n",
      "Epoch 50/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1009 - accuracy: 0.9756 - val_loss: 0.1936 - val_accuracy: 0.9484\n",
      "Epoch 51/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0658 - accuracy: 0.9856 - val_loss: 0.0821 - val_accuracy: 0.9859\n",
      "Epoch 52/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1320 - accuracy: 0.9704 - val_loss: 0.1388 - val_accuracy: 0.9531\n",
      "Epoch 53/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1106 - accuracy: 0.9719 - val_loss: 0.1000 - val_accuracy: 0.9812\n",
      "Epoch 54/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1136 - accuracy: 0.9631 - val_loss: 0.0665 - val_accuracy: 0.9765\n",
      "Epoch 55/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1172 - accuracy: 0.9651 - val_loss: 0.1165 - val_accuracy: 0.9718\n",
      "Epoch 56/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0866 - accuracy: 0.9699 - val_loss: 0.1564 - val_accuracy: 0.9577\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1286 - accuracy: 0.9670 - val_loss: 0.1679 - val_accuracy: 0.9812\n",
      "Epoch 58/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1051 - accuracy: 0.9684 - val_loss: 0.0984 - val_accuracy: 0.9765\n",
      "Epoch 59/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0982 - accuracy: 0.9656 - val_loss: 0.0216 - val_accuracy: 0.9953\n",
      "Epoch 60/500\n",
      "266/266 [==============================] - 4s 13ms/step - loss: 0.1005 - accuracy: 0.9732 - val_loss: 0.0954 - val_accuracy: 0.9765\n",
      "Epoch 61/500\n",
      "266/266 [==============================] - 4s 13ms/step - loss: 0.0999 - accuracy: 0.9730 - val_loss: 0.1347 - val_accuracy: 0.9765\n",
      "Epoch 62/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0659 - accuracy: 0.9809 - val_loss: 0.1738 - val_accuracy: 0.9671\n",
      "Epoch 63/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0933 - accuracy: 0.9728 - val_loss: 0.0677 - val_accuracy: 0.9859\n",
      "Epoch 64/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0823 - accuracy: 0.9747 - val_loss: 0.1325 - val_accuracy: 0.9812\n",
      "Epoch 65/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0875 - accuracy: 0.9721 - val_loss: 0.1878 - val_accuracy: 0.9577\n",
      "Epoch 66/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0681 - accuracy: 0.9802 - val_loss: 0.1233 - val_accuracy: 0.9624\n",
      "Epoch 67/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0905 - accuracy: 0.9735 - val_loss: 0.0731 - val_accuracy: 0.9859\n",
      "Epoch 68/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0984 - accuracy: 0.9676 - val_loss: 0.0700 - val_accuracy: 0.9859\n",
      "Epoch 69/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0730 - accuracy: 0.9761 - val_loss: 0.0825 - val_accuracy: 0.9671\n",
      "Epoch 70/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0646 - accuracy: 0.9769 - val_loss: 0.1104 - val_accuracy: 0.9624\n",
      "Epoch 71/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0896 - accuracy: 0.9647 - val_loss: 0.0847 - val_accuracy: 0.9859\n",
      "Epoch 72/500\n",
      "266/266 [==============================] - 4s 13ms/step - loss: 0.0992 - accuracy: 0.9781 - val_loss: 0.0454 - val_accuracy: 0.9906\n",
      "Epoch 73/500\n",
      "266/266 [==============================] - 4s 13ms/step - loss: 0.0754 - accuracy: 0.9738 - val_loss: 0.2166 - val_accuracy: 0.9624\n",
      "Epoch 74/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.1262 - accuracy: 0.9807 - val_loss: 0.0463 - val_accuracy: 0.9812\n",
      "Epoch 75/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0873 - accuracy: 0.9732 - val_loss: 0.0747 - val_accuracy: 0.9859\n",
      "Epoch 76/500\n",
      "266/266 [==============================] - 4s 13ms/step - loss: 0.0805 - accuracy: 0.9770 - val_loss: 0.0465 - val_accuracy: 0.9906\n",
      "Epoch 77/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0851 - accuracy: 0.9784 - val_loss: 0.0852 - val_accuracy: 0.9765\n",
      "Epoch 78/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0921 - accuracy: 0.9759 - val_loss: 0.0509 - val_accuracy: 0.9859\n",
      "Epoch 79/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0676 - accuracy: 0.9843 - val_loss: 0.0660 - val_accuracy: 0.9812\n",
      "Epoch 80/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0825 - accuracy: 0.9738 - val_loss: 0.0630 - val_accuracy: 0.9765\n",
      "Epoch 81/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0766 - accuracy: 0.9737 - val_loss: 0.0992 - val_accuracy: 0.9859\n",
      "Epoch 82/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0517 - accuracy: 0.9807 - val_loss: 0.0783 - val_accuracy: 0.9765\n",
      "Epoch 83/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0606 - accuracy: 0.9801 - val_loss: 0.0425 - val_accuracy: 0.9859\n",
      "Epoch 84/500\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0751 - accuracy: 0.9878 - val_loss: 0.0350 - val_accuracy: 0.9859\n",
      "Epoch 85/500\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.0818 - accuracy: 0.9756 - val_loss: 0.0520 - val_accuracy: 0.9812\n",
      "Epoch 86/500\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0666 - accuracy: 0.9788 - val_loss: 0.0360 - val_accuracy: 0.9812\n",
      "Epoch 87/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0679 - accuracy: 0.9815 - val_loss: 0.0788 - val_accuracy: 0.9765\n",
      "Epoch 88/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0524 - accuracy: 0.9875 - val_loss: 0.0207 - val_accuracy: 0.9906\n",
      "Epoch 89/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0333 - accuracy: 0.9874 - val_loss: 0.0437 - val_accuracy: 0.9812\n",
      "Epoch 90/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0811 - accuracy: 0.9715 - val_loss: 0.0198 - val_accuracy: 0.9953\n",
      "Epoch 91/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1114 - accuracy: 0.9754 - val_loss: 0.0905 - val_accuracy: 0.9859\n",
      "Epoch 92/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0722 - accuracy: 0.9790 - val_loss: 0.0712 - val_accuracy: 0.9812\n",
      "Epoch 93/500\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0765 - accuracy: 0.9829 - val_loss: 0.0574 - val_accuracy: 0.9859\n",
      "Epoch 94/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0480 - accuracy: 0.9796 - val_loss: 0.0258 - val_accuracy: 0.9906\n",
      "Epoch 95/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0780 - accuracy: 0.9773 - val_loss: 0.0193 - val_accuracy: 0.9859\n",
      "Epoch 96/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0648 - accuracy: 0.9855 - val_loss: 0.0486 - val_accuracy: 0.9812\n",
      "Epoch 97/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0849 - accuracy: 0.9751 - val_loss: 0.0659 - val_accuracy: 0.9812\n",
      "Epoch 98/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0406 - accuracy: 0.9873 - val_loss: 0.0705 - val_accuracy: 0.9718\n",
      "Epoch 99/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0421 - accuracy: 0.9794 - val_loss: 0.0225 - val_accuracy: 0.9906\n",
      "Epoch 100/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.1476 - accuracy: 0.9655 - val_loss: 0.0289 - val_accuracy: 0.9906\n",
      "Epoch 101/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0538 - accuracy: 0.9847 - val_loss: 0.0264 - val_accuracy: 0.9953\n",
      "Epoch 102/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.1011 - accuracy: 0.9808 - val_loss: 0.0976 - val_accuracy: 0.9718ss: 0.1046 - \n",
      "Epoch 103/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0783 - accuracy: 0.9815 - val_loss: 0.0348 - val_accuracy: 0.9859\n",
      "Epoch 104/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0851 - accuracy: 0.9725 - val_loss: 0.0319 - val_accuracy: 0.9812\n",
      "Epoch 105/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0324 - accuracy: 0.9906 - val_loss: 0.0714 - val_accuracy: 0.9906\n",
      "Epoch 106/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0549 - accuracy: 0.9885 - val_loss: 0.0198 - val_accuracy: 0.9906\n",
      "Epoch 107/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0629 - accuracy: 0.9865 - val_loss: 0.0812 - val_accuracy: 0.9765\n",
      "Epoch 108/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0572 - accuracy: 0.9845 - val_loss: 0.0601 - val_accuracy: 0.9812\n",
      "Epoch 109/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0593 - accuracy: 0.9837 - val_loss: 0.0699 - val_accuracy: 0.9906\n",
      "Epoch 110/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0852 - accuracy: 0.9767 - val_loss: 0.0842 - val_accuracy: 0.9812\n",
      "Epoch 111/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0673 - accuracy: 0.9834 - val_loss: 0.0281 - val_accuracy: 0.9859\n",
      "Epoch 112/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0444 - accuracy: 0.9863 - val_loss: 0.0883 - val_accuracy: 0.9718\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0500 - accuracy: 0.9774 - val_loss: 0.0982 - val_accuracy: 0.9812\n",
      "Epoch 114/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0549 - accuracy: 0.9837 - val_loss: 0.0477 - val_accuracy: 0.9859\n",
      "Epoch 115/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 0.0478 - val_accuracy: 0.9859\n",
      "Epoch 116/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0294 - accuracy: 0.9927 - val_loss: 0.0311 - val_accuracy: 0.9859\n",
      "Epoch 117/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0389 - accuracy: 0.9889 - val_loss: 0.0084 - val_accuracy: 0.9953\n",
      "Epoch 118/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0419 - accuracy: 0.9892 - val_loss: 0.0220 - val_accuracy: 0.9953\n",
      "Epoch 119/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0259 - accuracy: 0.9945 - val_loss: 0.0386 - val_accuracy: 0.9812\n",
      "Epoch 120/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0440 - accuracy: 0.9904 - val_loss: 0.0706 - val_accuracy: 0.9765\n",
      "Epoch 121/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0581 - accuracy: 0.9844 - val_loss: 0.0493 - val_accuracy: 0.9859\n",
      "Epoch 122/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0584 - accuracy: 0.9884 - val_loss: 0.1024 - val_accuracy: 0.9765\n",
      "Epoch 123/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0815 - accuracy: 0.9823 - val_loss: 0.0724 - val_accuracy: 0.9812\n",
      "Epoch 124/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0609 - accuracy: 0.9794 - val_loss: 0.0662 - val_accuracy: 0.9812\n",
      "Epoch 125/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0428 - accuracy: 0.9847 - val_loss: 0.1263 - val_accuracy: 0.9718\n",
      "Epoch 126/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0805 - accuracy: 0.9714 - val_loss: 0.0823 - val_accuracy: 0.9906\n",
      "Epoch 127/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0713 - accuracy: 0.9833 - val_loss: 0.0277 - val_accuracy: 0.9906\n",
      "Epoch 128/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0585 - accuracy: 0.9882 - val_loss: 0.0265 - val_accuracy: 0.9906\n",
      "Epoch 129/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0270 - accuracy: 0.9928 - val_loss: 0.0553 - val_accuracy: 0.9859\n",
      "Epoch 130/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0804 - accuracy: 0.9829 - val_loss: 0.0285 - val_accuracy: 0.9906\n",
      "Epoch 131/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0478 - accuracy: 0.9922 - val_loss: 0.0725 - val_accuracy: 0.9859\n",
      "Epoch 132/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0637 - accuracy: 0.9890 - val_loss: 0.0216 - val_accuracy: 0.9906\n",
      "Epoch 133/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0325 - accuracy: 0.9926 - val_loss: 0.0427 - val_accuracy: 0.9859\n",
      "Epoch 134/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0170 - accuracy: 0.9924 - val_loss: 0.0548 - val_accuracy: 0.9859\n",
      "Epoch 135/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0484 - accuracy: 0.9783 - val_loss: 0.0167 - val_accuracy: 0.9906\n",
      "Epoch 136/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.0909 - val_accuracy: 0.9812\n",
      "Epoch 137/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0270 - accuracy: 0.9884 - val_loss: 0.0665 - val_accuracy: 0.9859\n",
      "Epoch 138/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0771 - accuracy: 0.9829 - val_loss: 0.0278 - val_accuracy: 0.9906\n",
      "Epoch 139/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0309 - accuracy: 0.9910 - val_loss: 0.0547 - val_accuracy: 0.9906\n",
      "Epoch 140/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0313 - accuracy: 0.9909 - val_loss: 0.0566 - val_accuracy: 0.9718\n",
      "Epoch 141/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0320 - accuracy: 0.9858 - val_loss: 0.0345 - val_accuracy: 0.9859\n",
      "Epoch 142/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0270 - accuracy: 0.9909 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0551 - accuracy: 0.9816 - val_loss: 0.0518 - val_accuracy: 0.9906\n",
      "Epoch 144/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0464 - accuracy: 0.9864 - val_loss: 0.1565 - val_accuracy: 0.9859\n",
      "Epoch 145/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0940 - accuracy: 0.9761 - val_loss: 0.0356 - val_accuracy: 0.9859\n",
      "Epoch 146/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0463 - accuracy: 0.9851 - val_loss: 0.1009 - val_accuracy: 0.9859\n",
      "Epoch 147/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.0594 - val_accuracy: 0.9906\n",
      "Epoch 148/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0383 - accuracy: 0.9891 - val_loss: 0.0255 - val_accuracy: 0.9953\n",
      "Epoch 149/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 0.0105 - val_accuracy: 0.9953\n",
      "Epoch 150/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0563 - accuracy: 0.9857 - val_loss: 0.0313 - val_accuracy: 0.9859\n",
      "Epoch 151/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0595 - accuracy: 0.9859 - val_loss: 0.0145 - val_accuracy: 0.9953\n",
      "Epoch 152/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0557 - accuracy: 0.9832 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.0245 - val_accuracy: 0.9953\n",
      "Epoch 154/500\n",
      "266/266 [==============================] - 5s 16ms/step - loss: 0.0438 - accuracy: 0.9888 - val_loss: 0.0380 - val_accuracy: 0.9906\n",
      "Epoch 155/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0433 - accuracy: 0.9917 - val_loss: 0.0233 - val_accuracy: 0.9906\n",
      "Epoch 156/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0772 - accuracy: 0.9767 - val_loss: 0.0635 - val_accuracy: 0.9859\n",
      "Epoch 157/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.0588 - val_accuracy: 0.9859\n",
      "Epoch 158/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0692 - accuracy: 0.9800 - val_loss: 0.1555 - val_accuracy: 0.9765\n",
      "Epoch 159/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0537 - accuracy: 0.9851 - val_loss: 0.0401 - val_accuracy: 0.9906\n",
      "Epoch 160/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.0489 - val_accuracy: 0.9812\n",
      "Epoch 161/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0541 - accuracy: 0.9843 - val_loss: 0.0201 - val_accuracy: 0.9906\n",
      "Epoch 162/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0659 - accuracy: 0.9891 - val_loss: 0.0143 - val_accuracy: 0.9953\n",
      "Epoch 163/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0728 - accuracy: 0.9830 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0541 - accuracy: 0.9882 - val_loss: 0.0124 - val_accuracy: 0.9953\n",
      "Epoch 165/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0260 - accuracy: 0.9925 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0317 - accuracy: 0.9883 - val_loss: 0.0137 - val_accuracy: 0.9953\n",
      "Epoch 167/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0564 - accuracy: 0.9887 - val_loss: 0.0325 - val_accuracy: 0.9953\n",
      "Epoch 168/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0485 - accuracy: 0.9899 - val_loss: 0.0258 - val_accuracy: 0.9859\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0433 - accuracy: 0.9823 - val_loss: 0.0258 - val_accuracy: 0.9906\n",
      "Epoch 170/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0374 - accuracy: 0.9916 - val_loss: 0.0091 - val_accuracy: 0.9906\n",
      "Epoch 171/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.0104 - val_accuracy: 0.9953\n",
      "Epoch 172/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0354 - accuracy: 0.9870 - val_loss: 0.0414 - val_accuracy: 0.9906\n",
      "Epoch 173/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0263 - val_accuracy: 0.9859\n",
      "Epoch 174/500\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0772 - accuracy: 0.9874 - val_loss: 0.0105 - val_accuracy: 0.9953\n",
      "Epoch 175/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0350 - accuracy: 0.9857 - val_loss: 0.0462 - val_accuracy: 0.9906\n",
      "Epoch 176/500\n",
      "266/266 [==============================] - 5s 20ms/step - loss: 0.0675 - accuracy: 0.9877 - val_loss: 0.0569 - val_accuracy: 0.9812\n",
      "Epoch 177/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0339 - accuracy: 0.9850 - val_loss: 0.0070 - val_accuracy: 0.9953\n",
      "Epoch 178/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0450 - accuracy: 0.9944 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0165 - accuracy: 0.9938 - val_loss: 0.0159 - val_accuracy: 0.9906\n",
      "Epoch 180/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0651 - accuracy: 0.9822 - val_loss: 0.0260 - val_accuracy: 0.9859\n",
      "Epoch 181/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0272 - accuracy: 0.9904 - val_loss: 0.0465 - val_accuracy: 0.9906\n",
      "Epoch 182/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0494 - accuracy: 0.9832 - val_loss: 0.0310 - val_accuracy: 0.9953\n",
      "Epoch 183/500\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0463 - accuracy: 0.9914 - val_loss: 0.0172 - val_accuracy: 0.9953\n",
      "Epoch 184/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0357 - accuracy: 0.9864 - val_loss: 0.0254 - val_accuracy: 0.9859\n",
      "Epoch 185/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0060 - val_accuracy: 0.9953\n",
      "Epoch 186/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0335 - accuracy: 0.9900 - val_loss: 0.0352 - val_accuracy: 0.9859\n",
      "Epoch 187/500\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0251 - accuracy: 0.9868 - val_loss: 0.0900 - val_accuracy: 0.9859\n",
      "Epoch 188/500\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0302 - accuracy: 0.9914 - val_loss: 0.0574 - val_accuracy: 0.9812\n",
      "Epoch 189/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0736 - accuracy: 0.9865 - val_loss: 0.0161 - val_accuracy: 0.9953\n",
      "Epoch 190/500\n",
      "266/266 [==============================] - 5s 16ms/step - loss: 0.0347 - accuracy: 0.9886 - val_loss: 0.0062 - val_accuracy: 0.9953\n",
      "Epoch 191/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0211 - accuracy: 0.9923 - val_loss: 0.0211 - val_accuracy: 0.9953\n",
      "Epoch 192/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 0.0397 - val_accuracy: 0.9953\n",
      "Epoch 193/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0295 - accuracy: 0.9902 - val_loss: 0.0604 - val_accuracy: 0.9859\n",
      "Epoch 194/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.0547 - val_accuracy: 0.9906\n",
      "Epoch 195/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1023 - accuracy: 0.9816 - val_loss: 0.0456 - val_accuracy: 0.9859\n",
      "Epoch 196/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0181 - accuracy: 0.9926 - val_loss: 0.0181 - val_accuracy: 0.9906\n",
      "Epoch 197/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0502 - accuracy: 0.9843 - val_loss: 0.1077 - val_accuracy: 0.9765\n",
      "Epoch 198/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0866 - accuracy: 0.9849 - val_loss: 0.1041 - val_accuracy: 0.9859\n",
      "Epoch 199/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0338 - accuracy: 0.9897 - val_loss: 0.0454 - val_accuracy: 0.9812\n",
      "Epoch 200/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0584 - accuracy: 0.9790 - val_loss: 0.0287 - val_accuracy: 0.9906\n",
      "Epoch 201/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0487 - accuracy: 0.9898 - val_loss: 0.0707 - val_accuracy: 0.9906\n",
      "Epoch 202/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0392 - accuracy: 0.9842 - val_loss: 0.0786 - val_accuracy: 0.9765\n",
      "Epoch 203/500\n",
      "266/266 [==============================] - 3s 13ms/step - loss: 0.0310 - accuracy: 0.9862 - val_loss: 0.0205 - val_accuracy: 0.9953\n",
      "Epoch 204/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0471 - accuracy: 0.9893 - val_loss: 0.0153 - val_accuracy: 0.9906\n",
      "Epoch 205/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0400 - accuracy: 0.9856 - val_loss: 0.0166 - val_accuracy: 0.9906\n",
      "Epoch 206/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0341 - accuracy: 0.9908 - val_loss: 0.0417 - val_accuracy: 0.9906\n",
      "Epoch 207/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0529 - accuracy: 0.9872 - val_loss: 0.0484 - val_accuracy: 0.9906\n",
      "Epoch 208/500\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0193 - accuracy: 0.9928 - val_loss: 0.0259 - val_accuracy: 0.9906\n",
      "Epoch 209/500\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0235 - accuracy: 0.9903 - val_loss: 0.0502 - val_accuracy: 0.9906\n",
      "Epoch 210/500\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0040 - accuracy: 0.9980 - val_loss: 0.0497 - val_accuracy: 0.9859\n",
      "Epoch 211/500\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0319 - accuracy: 0.9930 - val_loss: 0.0196 - val_accuracy: 0.9953\n",
      "Epoch 212/500\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0453 - accuracy: 0.9866 - val_loss: 0.0136 - val_accuracy: 0.9953\n",
      "Epoch 213/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0289 - accuracy: 0.9944 - val_loss: 0.0557 - val_accuracy: 0.9906\n",
      "Epoch 214/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0531 - accuracy: 0.9881 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0322 - accuracy: 0.9936 - val_loss: 0.0107 - val_accuracy: 0.9953\n",
      "Epoch 216/500\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.0111 - val_accuracy: 0.9906\n",
      "Epoch 217/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 0.0537 - val_accuracy: 0.9859\n",
      "Epoch 218/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0355 - accuracy: 0.9907 - val_loss: 0.0146 - val_accuracy: 0.9953\n",
      "Epoch 219/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0292 - accuracy: 0.9964 - val_loss: 0.0342 - val_accuracy: 0.9906\n",
      "Epoch 220/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0540 - accuracy: 0.9859 - val_loss: 0.0468 - val_accuracy: 0.9859\n",
      "Epoch 221/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0405 - accuracy: 0.9916 - val_loss: 0.0218 - val_accuracy: 0.9953\n",
      "Epoch 222/500\n",
      "266/266 [==============================] - 7s 24ms/step - loss: 0.0221 - accuracy: 0.9955 - val_loss: 0.0082 - val_accuracy: 0.9953\n",
      "Epoch 223/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0388 - accuracy: 0.9903 - val_loss: 0.0392 - val_accuracy: 0.9859\n",
      "Epoch 224/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.0147 - val_accuracy: 0.9953\n",
      "Epoch 225/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0462 - accuracy: 0.9922 - val_loss: 0.0227 - val_accuracy: 0.9859\n",
      "Epoch 226/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0231 - accuracy: 0.9934 - val_loss: 0.0404 - val_accuracy: 0.9906\n",
      "Epoch 227/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0252 - accuracy: 0.9945 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0565 - accuracy: 0.9932 - val_loss: 0.0411 - val_accuracy: 0.9953\n",
      "Epoch 229/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0603 - accuracy: 0.9873 - val_loss: 0.0052 - val_accuracy: 0.9953\n",
      "Epoch 230/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0268 - accuracy: 0.9932 - val_loss: 0.0145 - val_accuracy: 0.9953\n",
      "Epoch 231/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0677 - accuracy: 0.9823 - val_loss: 0.0018 - val_accuracy: 1.0000 - \n",
      "Epoch 232/500\n",
      "266/266 [==============================] - 6s 20ms/step - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.0445 - val_accuracy: 0.9859\n",
      "Epoch 233/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0306 - accuracy: 0.9908 - val_loss: 0.0122 - val_accuracy: 0.9906\n",
      "Epoch 234/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0282 - accuracy: 0.9940 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0101 - val_accuracy: 0.9953\n",
      "Epoch 236/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0099 - accuracy: 0.9962 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0187 - accuracy: 0.9916 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0185 - accuracy: 0.9934 - val_loss: 0.0532 - val_accuracy: 0.9812\n",
      "Epoch 239/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0192 - accuracy: 0.9931 - val_loss: 0.0397 - val_accuracy: 0.9859\n",
      "Epoch 240/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0236 - accuracy: 0.9963 - val_loss: 0.0654 - val_accuracy: 0.9859\n",
      "Epoch 241/500\n",
      "266/266 [==============================] - 7s 24ms/step - loss: 0.0418 - accuracy: 0.9884 - val_loss: 0.0088 - val_accuracy: 0.9953\n",
      "Epoch 242/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0166 - accuracy: 0.9959 - val_loss: 0.0364 - val_accuracy: 0.9906\n",
      "Epoch 243/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0265 - accuracy: 0.9891 - val_loss: 0.0409 - val_accuracy: 0.9859\n",
      "Epoch 244/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0454 - accuracy: 0.9919 - val_loss: 0.0066 - val_accuracy: 0.9953\n",
      "Epoch 245/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0262 - accuracy: 0.9927 - val_loss: 0.0720 - val_accuracy: 0.9906\n",
      "Epoch 246/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0120 - accuracy: 0.9931 - val_loss: 0.0179 - val_accuracy: 0.9953\n",
      "Epoch 247/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0297 - accuracy: 0.9931 - val_loss: 0.0429 - val_accuracy: 0.9953\n",
      "Epoch 248/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0311 - accuracy: 0.9918 - val_loss: 0.0317 - val_accuracy: 0.9953\n",
      "Epoch 249/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0396 - accuracy: 0.9825 - val_loss: 0.0176 - val_accuracy: 0.9953\n",
      "Epoch 250/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.0763 - val_accuracy: 0.9812\n",
      "Epoch 251/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.0592 - val_accuracy: 0.9859\n",
      "Epoch 252/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.0235 - val_accuracy: 0.9953\n",
      "Epoch 253/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0749 - val_accuracy: 0.9953\n",
      "Epoch 254/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0585 - accuracy: 0.9838 - val_loss: 0.0501 - val_accuracy: 0.9906\n",
      "Epoch 255/500\n",
      "266/266 [==============================] - 6s 20ms/step - loss: 0.0187 - accuracy: 0.9982 - val_loss: 5.1183e-04 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0270 - accuracy: 0.9938 - val_loss: 0.0183 - val_accuracy: 0.9953\n",
      "Epoch 257/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0345 - accuracy: 0.9870 - val_loss: 0.1031 - val_accuracy: 0.9906\n",
      "Epoch 258/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0356 - accuracy: 0.9888 - val_loss: 0.0628 - val_accuracy: 0.9906\n",
      "Epoch 259/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0369 - accuracy: 0.9915 - val_loss: 0.0426 - val_accuracy: 0.9812\n",
      "Epoch 260/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0416 - accuracy: 0.9968 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0187 - accuracy: 0.9938 - val_loss: 0.0181 - val_accuracy: 0.9953\n",
      "Epoch 262/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0138 - accuracy: 0.9930 - val_loss: 0.0463 - val_accuracy: 0.9906\n",
      "Epoch 263/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0610 - accuracy: 0.9854 - val_loss: 0.0090 - val_accuracy: 0.9953\n",
      "Epoch 264/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0206 - accuracy: 0.9891 - val_loss: 0.0073 - val_accuracy: 0.9953\n",
      "Epoch 265/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0395 - accuracy: 0.9881 - val_loss: 0.0204 - val_accuracy: 0.9906\n",
      "Epoch 266/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0153 - accuracy: 0.9933 - val_loss: 0.0900 - val_accuracy: 0.9812\n",
      "Epoch 267/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0329 - val_accuracy: 0.9906\n",
      "Epoch 268/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0316 - accuracy: 0.9921 - val_loss: 0.0664 - val_accuracy: 0.9812\n",
      "Epoch 269/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0200 - accuracy: 0.9920 - val_loss: 0.0369 - val_accuracy: 0.9906\n",
      "Epoch 270/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0096 - accuracy: 0.9941 - val_loss: 0.0076 - val_accuracy: 0.9953\n",
      "Epoch 272/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0741 - accuracy: 0.9888 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0502 - accuracy: 0.9809 - val_loss: 0.0169 - val_accuracy: 0.9906\n",
      "Epoch 274/500\n",
      "266/266 [==============================] - 6s 23ms/step - loss: 0.0190 - accuracy: 0.9970 - val_loss: 0.0199 - val_accuracy: 0.9953\n",
      "Epoch 275/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0395 - accuracy: 0.9888 - val_loss: 0.0666 - val_accuracy: 0.9859\n",
      "Epoch 276/500\n",
      "266/266 [==============================] - 6s 22ms/step - loss: 0.0230 - accuracy: 0.9959 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "266/266 [==============================] - 5s 20ms/step - loss: 0.0230 - accuracy: 0.9933 - val_loss: 0.0230 - val_accuracy: 0.9906\n",
      "Epoch 278/500\n",
      "266/266 [==============================] - 6s 24ms/step - loss: 0.0573 - accuracy: 0.9908 - val_loss: 4.3140e-04 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0050 - accuracy: 0.9952 - val_loss: 0.0153 - val_accuracy: 0.9953\n",
      "Epoch 280/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0285 - accuracy: 0.9933 - val_loss: 0.0673 - val_accuracy: 0.9812\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.0210 - val_accuracy: 0.9906\n",
      "Epoch 282/500\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0266 - accuracy: 0.9943 - val_loss: 0.0069 - val_accuracy: 0.9953\n",
      "Epoch 283/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0388 - accuracy: 0.9950 - val_loss: 0.0053 - val_accuracy: 0.9953\n",
      "Epoch 284/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0259 - accuracy: 0.9937 - val_loss: 0.0110 - val_accuracy: 0.9953\n",
      "Epoch 285/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0232 - accuracy: 0.9948 - val_loss: 0.0151 - val_accuracy: 0.9953\n",
      "Epoch 286/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0656 - accuracy: 0.9895 - val_loss: 2.5879e-04 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 8.4207e-05 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 8.5823e-04 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "266/266 [==============================] - 5s 20ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0061 - accuracy: 0.9965 - val_loss: 0.0142 - val_accuracy: 0.9906\n",
      "Epoch 292/500\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0145 - accuracy: 0.9946 - val_loss: 0.0263 - val_accuracy: 0.9953\n",
      "Epoch 293/500\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0494 - accuracy: 0.9876 - val_loss: 0.0093 - val_accuracy: 0.9953\n",
      "Epoch 294/500\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0133 - accuracy: 0.9934 - val_loss: 0.0081 - val_accuracy: 0.9953\n",
      "Epoch 295/500\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0453 - val_accuracy: 0.9906\n",
      "Epoch 296/500\n",
      "266/266 [==============================] - 5s 20ms/step - loss: 0.0156 - accuracy: 0.9971 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0264 - accuracy: 0.9943 - val_loss: 0.0090 - val_accuracy: 0.9906\n",
      "Epoch 298/500\n",
      "266/266 [==============================] - 5s 20ms/step - loss: 0.0229 - accuracy: 0.9914 - val_loss: 0.0109 - val_accuracy: 0.9953\n",
      "Epoch 299/500\n",
      "266/266 [==============================] - 5s 20ms/step - loss: 0.0201 - accuracy: 0.9896 - val_loss: 0.0086 - val_accuracy: 0.9953\n",
      "Epoch 300/500\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.0056 - val_accuracy: 0.9953\n",
      "Epoch 302/500\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 6.0404e-04 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0347 - accuracy: 0.9853 - val_loss: 0.0259 - val_accuracy: 0.9906\n",
      "Epoch 304/500\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 1.5518e-04 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0430 - val_accuracy: 0.9906\n",
      "Epoch 306/500\n",
      "266/266 [==============================] - 3s 13ms/step - loss: 0.0344 - accuracy: 0.9938 - val_loss: 7.5372e-05 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.0425 - accuracy: 0.9829 - val_loss: 0.0378 - val_accuracy: 0.9906\n",
      "Epoch 308/500\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.0154 - val_accuracy: 0.9953\n",
      "Epoch 309/500\n",
      "266/266 [==============================] - 3s 13ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 0.0441 - val_accuracy: 0.9906\n",
      "Epoch 310/500\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.0148 - accuracy: 0.9940 - val_loss: 0.0737 - val_accuracy: 0.9812\n",
      "Epoch 311/500\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.0241 - accuracy: 0.9921 - val_loss: 3.6237e-04 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "266/266 [==============================] - 3s 13ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0599 - accuracy: 0.9868 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0386 - accuracy: 0.9914 - val_loss: 0.0416 - val_accuracy: 0.9953\n",
      "Epoch 315/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0041 - val_accuracy: 0.9953\n",
      "Epoch 316/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0215 - accuracy: 0.9960 - val_loss: 0.0625 - val_accuracy: 0.9906\n",
      "Epoch 317/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0560 - val_accuracy: 0.9906\n",
      "Epoch 318/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0255 - accuracy: 0.9899 - val_loss: 0.0145 - val_accuracy: 0.9953\n",
      "Epoch 319/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0290 - accuracy: 0.9932 - val_loss: 5.1252e-04 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0701 - accuracy: 0.9916 - val_loss: 0.0402 - val_accuracy: 0.9906\n",
      "Epoch 321/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 0.0526 - val_accuracy: 0.9906\n",
      "Epoch 322/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0276 - val_accuracy: 0.9812\n",
      "Epoch 323/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0307 - accuracy: 0.9921 - val_loss: 0.0354 - val_accuracy: 0.9953\n",
      "Epoch 324/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0367 - accuracy: 0.9896 - val_loss: 0.0378 - val_accuracy: 0.9859\n",
      "Epoch 325/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0247 - accuracy: 0.9970 - val_loss: 0.0464 - val_accuracy: 0.9906\n",
      "Epoch 326/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0151 - accuracy: 0.9932 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.0781 - val_accuracy: 0.9906\n",
      "Epoch 328/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0158 - accuracy: 0.9981 - val_loss: 7.4320e-04 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0276 - accuracy: 0.9923 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0339 - accuracy: 0.9956 - val_loss: 0.0974 - val_accuracy: 0.9859\n",
      "Epoch 332/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0321 - accuracy: 0.9968 - val_loss: 0.0389 - val_accuracy: 0.9953\n",
      "Epoch 333/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.0474 - val_accuracy: 0.9906\n",
      "Epoch 335/500\n",
      "266/266 [==============================] - 3s 12ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.0199 - val_accuracy: 0.9953\n",
      "Epoch 336/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0220 - accuracy: 0.9947 - val_loss: 0.0034 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0348 - accuracy: 0.9894 - val_loss: 0.0059 - val_accuracy: 0.9953\n",
      "Epoch 338/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0417 - accuracy: 0.9930 - val_loss: 0.0188 - val_accuracy: 0.9953\n",
      "Epoch 339/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0059 - val_accuracy: 0.9953\n",
      "Epoch 340/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0156 - accuracy: 0.9972 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0386 - accuracy: 0.9918 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0261 - accuracy: 0.9924 - val_loss: 0.0283 - val_accuracy: 0.9953\n",
      "Epoch 343/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 2.7495e-05 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0323 - val_accuracy: 0.9953\n",
      "Epoch 345/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 4.3417e-04 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0424 - accuracy: 0.9941 - val_loss: 0.0142 - val_accuracy: 0.9953\n",
      "Epoch 347/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0182 - accuracy: 0.9923 - val_loss: 0.0146 - val_accuracy: 0.9906\n",
      "Epoch 348/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0170 - val_accuracy: 0.9953\n",
      "Epoch 349/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.0242 - val_accuracy: 0.9906\n",
      "Epoch 350/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0214 - accuracy: 0.9913 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0340 - accuracy: 0.9945 - val_loss: 6.3499e-04 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0124 - val_accuracy: 0.9953\n",
      "Epoch 353/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0277 - accuracy: 0.9880 - val_loss: 0.0602 - val_accuracy: 0.9906\n",
      "Epoch 354/500\n",
      "266/266 [==============================] - 3s 9ms/step - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.0549 - val_accuracy: 0.9906\n",
      "Epoch 355/500\n",
      "266/266 [==============================] - 3s 10ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0145 - val_accuracy: 0.9953\n",
      "Epoch 356/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0572 - accuracy: 0.9845 - val_loss: 0.0074 - val_accuracy: 0.9953\n",
      "Epoch 357/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0261 - accuracy: 0.9943 - val_loss: 0.0280 - val_accuracy: 0.9953\n",
      "Epoch 358/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0366 - accuracy: 0.9925 - val_loss: 0.0459 - val_accuracy: 0.9859\n",
      "Epoch 359/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0113 - accuracy: 0.9929 - val_loss: 0.0761 - val_accuracy: 0.9953\n",
      "Epoch 360/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0360 - val_accuracy: 0.9906\n",
      "Epoch 361/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.0124 - val_accuracy: 0.9906\n",
      "Epoch 362/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0693 - accuracy: 0.9876 - val_loss: 0.0101 - val_accuracy: 0.9953\n",
      "Epoch 363/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.0216 - val_accuracy: 0.9953\n",
      "Epoch 364/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9953\n",
      "Epoch 365/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.0244 - val_accuracy: 0.9953\n",
      "Epoch 366/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0334 - accuracy: 0.9925 - val_loss: 0.0682 - val_accuracy: 0.9859\n",
      "Epoch 367/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0329 - accuracy: 0.9928 - val_loss: 0.0399 - val_accuracy: 0.9906\n",
      "Epoch 368/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0096 - val_accuracy: 0.9953\n",
      "Epoch 369/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.0114 - val_accuracy: 0.9906\n",
      "Epoch 370/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0302 - val_accuracy: 0.9953\n",
      "Epoch 371/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0167 - accuracy: 0.9907 - val_loss: 2.7636e-04 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0224 - accuracy: 0.9968 - val_loss: 0.0628 - val_accuracy: 0.9953\n",
      "Epoch 373/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0145 - accuracy: 0.9971 - val_loss: 4.1554e-04 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.0327 - val_accuracy: 0.9906\n",
      "Epoch 376/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 9.2958e-04 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.1131 - accuracy: 0.9875 - val_loss: 1.5587e-04 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.0212 - val_accuracy: 0.9953\n",
      "Epoch 379/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0299 - accuracy: 0.9958 - val_loss: 0.0261 - val_accuracy: 0.9953\n",
      "Epoch 380/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0381 - accuracy: 0.9916 - val_loss: 0.0129 - val_accuracy: 0.9906\n",
      "Epoch 381/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0463 - accuracy: 0.9938 - val_loss: 0.0100 - val_accuracy: 0.9953\n",
      "Epoch 382/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0329 - accuracy: 0.9901 - val_loss: 0.0468 - val_accuracy: 0.9859\n",
      "Epoch 383/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0252 - accuracy: 0.9965 - val_loss: 0.0035 - val_accuracy: 0.9953\n",
      "Epoch 384/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 5.9203e-04 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0058 - accuracy: 0.9997 - val_loss: 0.0316 - val_accuracy: 0.9906\n",
      "Epoch 386/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0228 - accuracy: 0.9976 - val_loss: 0.0234 - val_accuracy: 0.9906\n",
      "Epoch 387/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0114 - accuracy: 0.9982 - val_loss: 0.1511 - val_accuracy: 0.9859\n",
      "Epoch 389/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0799 - accuracy: 0.9904 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0224 - accuracy: 0.9969 - val_loss: 0.0491 - val_accuracy: 0.9906\n",
      "Epoch 391/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0215 - accuracy: 0.9981 - val_loss: 0.0246 - val_accuracy: 0.9906\n",
      "Epoch 392/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0177 - accuracy: 0.9961 - val_loss: 0.0532 - val_accuracy: 0.9906\n",
      "Epoch 393/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.0433 - val_accuracy: 0.9906\n",
      "Epoch 394/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 9.6577e-04 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0265 - val_accuracy: 0.9953\n",
      "Epoch 396/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0243 - accuracy: 0.9959 - val_loss: 3.1569e-04 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0237 - accuracy: 0.9959 - val_loss: 0.0066 - val_accuracy: 0.9953\n",
      "Epoch 398/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0121 - accuracy: 0.9940 - val_loss: 0.0992 - val_accuracy: 0.9906\n",
      "Epoch 399/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0143 - accuracy: 0.9933 - val_loss: 0.0853 - val_accuracy: 0.9859\n",
      "Epoch 400/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0089 - accuracy: 0.9988 - val_loss: 0.0319 - val_accuracy: 0.9953\n",
      "Epoch 401/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0764 - accuracy: 0.9867 - val_loss: 0.0956 - val_accuracy: 0.9812\n",
      "Epoch 402/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 0.0089 - val_accuracy: 0.9953\n",
      "Epoch 403/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0372 - accuracy: 0.9940 - val_loss: 1.2367e-04 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 0.0061 - val_accuracy: 0.9953\n",
      "Epoch 405/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0124 - accuracy: 0.9942 - val_loss: 4.1191e-04 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0177 - accuracy: 0.9955 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0210 - accuracy: 0.9905 - val_loss: 0.0322 - val_accuracy: 0.9953\n",
      "Epoch 408/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0118 - val_accuracy: 0.9906\n",
      "Epoch 409/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0113 - accuracy: 0.9936 - val_loss: 0.0221 - val_accuracy: 0.9953\n",
      "Epoch 410/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0478 - accuracy: 0.9897 - val_loss: 0.0436 - val_accuracy: 0.9953\n",
      "Epoch 411/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0323 - accuracy: 0.9906 - val_loss: 0.0598 - val_accuracy: 0.9859\n",
      "Epoch 412/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0363 - accuracy: 0.9933 - val_loss: 6.4461e-04 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0122 - accuracy: 0.9981 - val_loss: 4.4577e-04 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0644 - accuracy: 0.9954 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0259 - accuracy: 0.9943 - val_loss: 0.0104 - val_accuracy: 0.9953\n",
      "Epoch 417/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0360 - accuracy: 0.9924 - val_loss: 0.0059 - val_accuracy: 0.9953\n",
      "Epoch 418/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 3.3708e-04 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0049 - val_accuracy: 0.9953\n",
      "Epoch 420/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0251 - accuracy: 0.9973 - val_loss: 0.0441 - val_accuracy: 0.9906\n",
      "Epoch 421/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0431 - accuracy: 0.9930 - val_loss: 2.6290e-04 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0079 - accuracy: 0.9964 - val_loss: 0.0478 - val_accuracy: 0.9953\n",
      "Epoch 424/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0334 - accuracy: 0.9949 - val_loss: 0.0064 - val_accuracy: 0.9953\n",
      "Epoch 425/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0187 - accuracy: 0.9963 - val_loss: 0.0807 - val_accuracy: 0.9812\n",
      "Epoch 426/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0337 - accuracy: 0.9958 - val_loss: 0.0092 - val_accuracy: 0.9953\n",
      "Epoch 427/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 2.8225e-04 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0231 - accuracy: 0.9949 - val_loss: 3.8630e-04 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0195 - accuracy: 0.9966 - val_loss: 0.0884 - val_accuracy: 0.9859\n",
      "Epoch 430/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.0936 - val_accuracy: 0.9906\n",
      "Epoch 431/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0267 - accuracy: 0.9978 - val_loss: 0.0352 - val_accuracy: 0.9953\n",
      "Epoch 432/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0790 - accuracy: 0.9829 - val_loss: 0.0090 - val_accuracy: 0.9953\n",
      "Epoch 433/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0331 - accuracy: 0.9924 - val_loss: 0.0510 - val_accuracy: 0.9953\n",
      "Epoch 434/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0150 - accuracy: 0.9979 - val_loss: 0.0086 - val_accuracy: 0.9953\n",
      "Epoch 436/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0601 - accuracy: 0.9894 - val_loss: 0.0157 - val_accuracy: 0.9953\n",
      "Epoch 437/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0292 - accuracy: 0.9958 - val_loss: 0.0619 - val_accuracy: 0.9953\n",
      "Epoch 438/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0429 - accuracy: 0.9914 - val_loss: 0.0127 - val_accuracy: 0.9906\n",
      "Epoch 439/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.0062 - val_accuracy: 0.9953\n",
      "Epoch 440/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0587 - accuracy: 0.9920 - val_loss: 1.5644e-04 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0058 - val_accuracy: 0.9953\n",
      "Epoch 442/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.0295 - val_accuracy: 0.9953\n",
      "Epoch 443/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.0233 - val_accuracy: 0.9859\n",
      "Epoch 444/500\n",
      "266/266 [==============================] - 3s 9ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "266/266 [==============================] - 3s 13ms/step - loss: 0.0158 - accuracy: 0.9939 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.0438 - val_accuracy: 0.9906\n",
      "Epoch 447/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0111 - accuracy: 0.9992 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 2.4014e-04 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 3s 11ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 0.9953\n",
      "Epoch 450/500\n",
      "266/266 [==============================] - 2s 9ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.0116 - val_accuracy: 0.9953\n",
      "Epoch 451/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0199 - val_accuracy: 0.9953\n",
      "Epoch 452/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0114 - accuracy: 0.9926 - val_loss: 0.0141 - val_accuracy: 0.9953\n",
      "Epoch 453/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0143 - accuracy: 0.9980 - val_loss: 0.0915 - val_accuracy: 0.9906\n",
      "Epoch 455/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0202 - accuracy: 0.9972 - val_loss: 0.0390 - val_accuracy: 0.9953\n",
      "Epoch 456/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0017 - accuracy: 0.9987 - val_loss: 0.0155 - val_accuracy: 0.9953\n",
      "Epoch 457/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0553 - accuracy: 0.9915 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0280 - accuracy: 0.9958 - val_loss: 0.0542 - val_accuracy: 0.9812\n",
      "Epoch 459/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0339 - accuracy: 0.9938 - val_loss: 3.2979e-04 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0232 - accuracy: 0.9901 - val_loss: 0.0123 - val_accuracy: 0.9953\n",
      "Epoch 461/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0293 - accuracy: 0.9933 - val_loss: 0.0356 - val_accuracy: 0.9906\n",
      "Epoch 462/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 0.0170 - val_accuracy: 0.9953\n",
      "Epoch 463/500\n",
      "266/266 [==============================] - 2s 6ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0368 - val_accuracy: 0.9953\n",
      "Epoch 464/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 0.0154 - val_accuracy: 0.9953\n",
      "Epoch 465/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 7.9880e-05 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 3.6462e-05 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0102 - accuracy: 0.9983 - val_loss: 6.5545e-05 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0187 - accuracy: 0.9962 - val_loss: 2.7228e-05 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 0.0330 - val_accuracy: 0.9953\n",
      "Epoch 473/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0084 - accuracy: 0.9960 - val_loss: 6.4554e-06 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0087 - val_accuracy: 0.9953\n",
      "Epoch 475/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0047 - accuracy: 0.9995 - val_loss: 0.0138 - val_accuracy: 0.9906\n",
      "Epoch 476/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0516 - accuracy: 0.9910 - val_loss: 0.0405 - val_accuracy: 0.9953\n",
      "Epoch 477/500\n",
      "266/266 [==============================] - 2s 8ms/step - loss: 0.0204 - accuracy: 0.9960 - val_loss: 1.3228e-04 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0329 - accuracy: 0.9945 - val_loss: 9.3014e-07 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 6.6696e-05 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 1.6643e-05 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0251 - accuracy: 0.9950 - val_loss: 8.3172e-05 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.0893 - val_accuracy: 0.9906\n",
      "Epoch 483/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.1156 - val_accuracy: 0.9859\n",
      "Epoch 484/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 5.0885e-04 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0160 - accuracy: 0.9960 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0337 - val_accuracy: 0.9953\n",
      "Epoch 487/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0125 - val_accuracy: 0.9953\n",
      "Epoch 488/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.0125 - val_accuracy: 0.9953\n",
      "Epoch 489/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0181 - accuracy: 0.9929 - val_loss: 0.1036 - val_accuracy: 0.9953\n",
      "Epoch 490/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0161 - val_accuracy: 0.9953\n",
      "Epoch 491/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1355 - val_accuracy: 0.9953\n",
      "Epoch 492/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0279 - accuracy: 0.9932 - val_loss: 0.0119 - val_accuracy: 0.9953\n",
      "Epoch 493/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0028 - accuracy: 0.9978 - val_loss: 0.0057 - val_accuracy: 0.9953\n",
      "Epoch 494/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0466 - val_accuracy: 0.9953\n",
      "Epoch 495/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0251 - accuracy: 0.9947 - val_loss: 1.4561e-05 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 1.3321e-04 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 8.4065e-04 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0445 - accuracy: 0.9909 - val_loss: 1.7070e-04 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "266/266 [==============================] - 2s 7ms/step - loss: 0.0078 - accuracy: 0.9968 - val_loss: 0.0044 - val_accuracy: 0.9953\n"
     ]
    }
   ],
   "source": [
    "Batch_Size = 4\n",
    "Shift_Range = 1\n",
    "Brightness_Range = 0.3\n",
    "Rotation_Angle = 10\n",
    "ZoomRange = 0.4\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], \n",
    "                             height_shift_range=[-Shift_Range,Shift_Range],\n",
    "                             brightness_range=[1-Brightness_Range,1+Brightness_Range],\n",
    "                             zoom_range=[1-ZoomRange, 1+ZoomRange],\n",
    "                             rotation_range=Rotation_Angle)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, epochs = Epoch_Anz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learing result\n",
    " \n",
    "* Visualization of the training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "plt.semilogy(history.history['loss'])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model by hand\n",
    "\n",
    "* The following code uses the trained model to check the deviation for each picture.\n",
    "* x-axis walks through each pixel, y-axis shows the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Input_dir='ziffer_sortiert_resize'\n",
    "subdir = [\"NaN\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "res = []\n",
    "\n",
    "for aktsubdir in subdir:\n",
    "    files = glob.glob(Input_dir + '/' + aktsubdir + '\\*.jpg')\n",
    "    if aktsubdir == \"NaN\":\n",
    "        zw1 = -1\n",
    "    else:\n",
    "        zw1 = int(aktsubdir)\n",
    "    for aktfile in files:\n",
    "        test_image = Image.open(aktfile)\n",
    "        test_image = np.array(test_image, dtype=\"float32\")\n",
    "        img = np.reshape(test_image,[1,32,20,3])\n",
    "        classes = np.argmax(model.predict(img), axis=-1)\n",
    "        classes = classes[0]\n",
    "        if classes == 10: \n",
    "            classes = -1\n",
    "        zw2 = classes\n",
    "        zw3 = zw2 - zw1\n",
    "        res.append(np.array([zw1, zw2, zw3]))\n",
    "\n",
    "res = np.asarray(res)\n",
    "\n",
    "\n",
    "plt.plot(res[:,0])\n",
    "plt.plot(res[:,1])\n",
    "plt.title('Result')\n",
    "plt.ylabel('Digital Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['real','model'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Save the model to the file with the \"h5\" file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Muell\\AppData\\Local\\Temp\\tmpcmco5hzy\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1303008"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileName = TFliteNamingAndVersion\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Muell\\AppData\\Local\\Temp\\tmpw8nr1mzh\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Muell\\AppData\\Local\\Temp\\tmpw8nr1mzh\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "338112"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileName = TFliteNamingAndVersion + \"q\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def representative_dataset():\n",
    "    for _ in range(500):\n",
    "      data = np.random.rand(1, 32, 20, 3) * 255\n",
    "      yield [data.astype(np.float32)]\n",
    "        \n",
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter2.representative_dataset = representative_dataset\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter2.convert()\n",
    "\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check each image for expected and deviation\n",
    "* setting the switch \"only_deviation = true\" will only print the images for which the classification and the CNN-result deviates\n",
    "\n",
    "The output contains the following information:\n",
    "\n",
    "| Filename      | Expected Category           | Predicted Category        |\n",
    "|------------- |:-----------------------------:|--------------|\n",
    "| ziffer_sortiert_resize_NaN/5\\Ziffer_4_0034.jpg | 4  | -1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ziffer_sortiert_resize/0\\D6_2020-08-16_01-02-52.jpg 0 NaN\n",
      "ziffer_sortiert_resize/8\\D7_2020-08-14_00-01-25.jpg 8 9\n"
     ]
    }
   ],
   "source": [
    "Input_dir='ziffer_sortiert_resize'\n",
    "only_deviation = True\n",
    "\n",
    "subdir = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"NaN\"]\n",
    "\n",
    "for aktsubdir in subdir:\n",
    "    files = glob.glob(Input_dir + '/' + aktsubdir + '\\*.jpg')\n",
    "    expected_class = aktsubdir\n",
    "    for aktfile in files:\n",
    "        test_image = Image.open(aktfile)\n",
    "        test_image = np.array(test_image, dtype=\"float32\")\n",
    "        img = np.reshape(test_image,[1,32,20,3])\n",
    "        classes = np.argmax(model.predict(img), axis=-1)\n",
    "        classes = classes[0]\n",
    "        if classes == 10: \n",
    "            classes = \"NaN\"\n",
    "        if only_deviation == True:\n",
    "            if str(classes) != str(expected_class):\n",
    "                print(aktfile + \" \" + aktsubdir +  \" \" + str(classes))\n",
    "        else:\n",
    "            print(aktfile + \" \" + aktsubdir +  \" \" + str(classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the images shows, that this are border line images, which can be interpreted as a good digit or a faulty one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
