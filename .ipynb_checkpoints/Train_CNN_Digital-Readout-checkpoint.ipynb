{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Target of this code is to train a CNN network to classify images of a digital readout to the digits 0 to 9. Additionally a category \"NaN\" is introduced, to mark images that are not amibiguous.\n",
    "\n",
    "### Preparing the training\n",
    "* First all libraries are loaded\n",
    "    * It is assumed, that they are installed during the Python setup\n",
    "* matplotlib is set to print the output inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "    \n",
    "TFliteNamingAndVersion = \"dig1040s0\"     # Used for tflite Filename\n",
    "Training_Percentage = 0.2              # 0.0 = Use all Images for Training\n",
    "Epoch_Anz = 500\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import History \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image \n",
    "\n",
    "loss_ges = np.array([])\n",
    "val_loss_ges = np.array([])\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Inside subdirectories are expected from -1, 0, 1, ... 9 in which the pictures are sorted according to their values (=category)\n",
    "* Picture size must be 20x32 with 3 color channels (RGB)\n",
    "* The filename can be arbitrary\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected category for each image in the corresponding y_data[]\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) and split the data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1380, 32, 20, 3)\n",
      "(1380, 11)\n"
     ]
    }
   ],
   "source": [
    "Input_dir='ziffer_sortiert_resize'\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.*')\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "subdir = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"NaN\"]\n",
    "\n",
    "for aktsubdir in subdir:\n",
    "    files = glob.glob(Input_dir + '/' + aktsubdir + '/*.jpg')\n",
    "    if aktsubdir == \"NaN\":\n",
    "        category = 10                # NaN does not work --> convert to 10\n",
    "    else:\n",
    "        category = aktsubdir\n",
    "    for aktfile in files:\n",
    "        test_image = Image.open(aktfile)\n",
    "        test_image = np.array(test_image, dtype=\"float32\")\n",
    "        x_data.append(test_image)\n",
    "        y_data.append(np.array([category]))\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "y_data = to_categorical(y_data, 11)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "else:\n",
    "    X_train = x_data\n",
    "    y_train = y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The layout of the network ist a typcial CNN network with alternating **Conv2D** and **MaxPool2D** layers. Finished after **flattening** with additional **Dense** layer.\n",
    "\n",
    "#### Important\n",
    "* Shape of the input layer: (32, 20, 3)\n",
    "* Number of output layers: 11\n",
    "* As loss function \"categorical_crossentropy\" is choosen, as it is a categories task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 32, 20, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 20, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                5643      \n",
      "=================================================================\n",
      "Total params: 324,631\n",
      "Trainable params: 324,625\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(32,20,3)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dense(11, activation = \"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The input pictures are randomly scattered for brightness, pixel shift variations and rotation angle. This is implemented with a ImageDataGenerator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "345/345 [==============================] - 14s 28ms/step - loss: 2.1430 - accuracy: 0.3276 - val_loss: 1.6649 - val_accuracy: 0.4565\n",
      "Epoch 2/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 1.2640 - accuracy: 0.5929 - val_loss: 0.9053 - val_accuracy: 0.7355\n",
      "Epoch 3/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.9410 - accuracy: 0.7039 - val_loss: 0.7033 - val_accuracy: 0.7717\n",
      "Epoch 4/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.7426 - accuracy: 0.7799 - val_loss: 0.8453 - val_accuracy: 0.7572\n",
      "Epoch 5/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.6490 - accuracy: 0.7808 - val_loss: 0.5393 - val_accuracy: 0.8514\n",
      "Epoch 6/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.4642 - accuracy: 0.8579 - val_loss: 0.4291 - val_accuracy: 0.8877\n",
      "Epoch 7/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.5009 - accuracy: 0.8439 - val_loss: 0.4622 - val_accuracy: 0.8116\n",
      "Epoch 8/500\n",
      "345/345 [==============================] - 7s 19ms/step - loss: 0.4381 - accuracy: 0.8564 - val_loss: 0.4026 - val_accuracy: 0.8696\n",
      "Epoch 9/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.3814 - accuracy: 0.9143 - val_loss: 0.3559 - val_accuracy: 0.8913\n",
      "Epoch 10/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.3325 - accuracy: 0.8967 - val_loss: 0.4207 - val_accuracy: 0.8659\n",
      "Epoch 11/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.3339 - accuracy: 0.8932 - val_loss: 0.3654 - val_accuracy: 0.8768\n",
      "Epoch 12/500\n",
      "345/345 [==============================] - 7s 19ms/step - loss: 0.3363 - accuracy: 0.9016 - val_loss: 0.2890 - val_accuracy: 0.9203\n",
      "Epoch 13/500\n",
      "345/345 [==============================] - 7s 19ms/step - loss: 0.2996 - accuracy: 0.9097 - val_loss: 0.3824 - val_accuracy: 0.9022\n",
      "Epoch 14/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.2748 - accuracy: 0.9111 - val_loss: 0.4294 - val_accuracy: 0.8768\n",
      "Epoch 15/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.2557 - accuracy: 0.9217 - val_loss: 0.2022 - val_accuracy: 0.9312\n",
      "Epoch 16/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.2663 - accuracy: 0.9079 - val_loss: 0.1677 - val_accuracy: 0.9348\n",
      "Epoch 17/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.2713 - accuracy: 0.9067 - val_loss: 0.2282 - val_accuracy: 0.9167\n",
      "Epoch 18/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.2128 - accuracy: 0.9397 - val_loss: 0.1967 - val_accuracy: 0.9312\n",
      "Epoch 19/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.1762 - accuracy: 0.9469 - val_loss: 0.1936 - val_accuracy: 0.9348\n",
      "Epoch 20/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.2366 - accuracy: 0.9205 - val_loss: 0.2921 - val_accuracy: 0.9022\n",
      "Epoch 21/500\n",
      "345/345 [==============================] - 7s 19ms/step - loss: 0.2145 - accuracy: 0.9410 - val_loss: 0.1921 - val_accuracy: 0.9384\n",
      "Epoch 22/500\n",
      "345/345 [==============================] - 7s 19ms/step - loss: 0.1794 - accuracy: 0.9382 - val_loss: 0.2168 - val_accuracy: 0.9203\n",
      "Epoch 23/500\n",
      "345/345 [==============================] - 7s 19ms/step - loss: 0.1983 - accuracy: 0.9416 - val_loss: 0.2105 - val_accuracy: 0.9493\n",
      "Epoch 24/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.1447 - accuracy: 0.9583 - val_loss: 0.1730 - val_accuracy: 0.9457\n",
      "Epoch 25/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.1488 - accuracy: 0.9485 - val_loss: 0.2769 - val_accuracy: 0.9457\n",
      "Epoch 26/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.1940 - accuracy: 0.9476 - val_loss: 0.2028 - val_accuracy: 0.9384\n",
      "Epoch 27/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.1404 - accuracy: 0.9532 - val_loss: 0.2076 - val_accuracy: 0.9348\n",
      "Epoch 28/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.1668 - accuracy: 0.9467 - val_loss: 0.1519 - val_accuracy: 0.9457\n",
      "Epoch 29/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.1484 - accuracy: 0.9583 - val_loss: 0.1316 - val_accuracy: 0.9601\n",
      "Epoch 30/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.1659 - accuracy: 0.9449 - val_loss: 0.1787 - val_accuracy: 0.9529\n",
      "Epoch 31/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.1559 - accuracy: 0.9570 - val_loss: 0.3440 - val_accuracy: 0.9275\n",
      "Epoch 32/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.1402 - accuracy: 0.9599 - val_loss: 0.1688 - val_accuracy: 0.9529\n",
      "Epoch 33/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.1547 - accuracy: 0.9566 - val_loss: 0.0787 - val_accuracy: 0.9746\n",
      "Epoch 34/500\n",
      "345/345 [==============================] - 7s 19ms/step - loss: 0.1038 - accuracy: 0.9686 - val_loss: 0.1933 - val_accuracy: 0.9529\n",
      "Epoch 35/500\n",
      "345/345 [==============================] - 6s 19ms/step - loss: 0.1609 - accuracy: 0.9612 - val_loss: 0.1303 - val_accuracy: 0.9710\n",
      "Epoch 36/500\n",
      "345/345 [==============================] - 6s 19ms/step - loss: 0.1518 - accuracy: 0.9642 - val_loss: 0.0855 - val_accuracy: 0.9746\n",
      "Epoch 37/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.1481 - accuracy: 0.9528 - val_loss: 0.1644 - val_accuracy: 0.9565\n",
      "Epoch 38/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.1526 - accuracy: 0.9572 - val_loss: 0.0928 - val_accuracy: 0.9746\n",
      "Epoch 39/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.1310 - accuracy: 0.9584 - val_loss: 0.1478 - val_accuracy: 0.9493\n",
      "Epoch 40/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.1547 - accuracy: 0.9574 - val_loss: 0.1046 - val_accuracy: 0.9638\n",
      "Epoch 41/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.1006 - accuracy: 0.9652 - val_loss: 0.1122 - val_accuracy: 0.9565\n",
      "Epoch 42/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0938 - accuracy: 0.9717 - val_loss: 0.1422 - val_accuracy: 0.9493\n",
      "Epoch 43/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.1421 - accuracy: 0.9621 - val_loss: 0.3570 - val_accuracy: 0.9348\n",
      "Epoch 44/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.1380 - accuracy: 0.9524 - val_loss: 0.1599 - val_accuracy: 0.9638\n",
      "Epoch 45/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.1157 - accuracy: 0.9624 - val_loss: 0.2238 - val_accuracy: 0.9529\n",
      "Epoch 46/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0785 - accuracy: 0.9769 - val_loss: 0.1049 - val_accuracy: 0.9783\n",
      "Epoch 47/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.1152 - accuracy: 0.9685 - val_loss: 0.1960 - val_accuracy: 0.9348\n",
      "Epoch 48/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0927 - accuracy: 0.9729 - val_loss: 0.1698 - val_accuracy: 0.9565\n",
      "Epoch 49/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.1511 - accuracy: 0.9641 - val_loss: 0.1218 - val_accuracy: 0.9638\n",
      "Epoch 50/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0963 - accuracy: 0.9684 - val_loss: 0.0905 - val_accuracy: 0.9710\n",
      "Epoch 51/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0923 - accuracy: 0.9702 - val_loss: 0.1310 - val_accuracy: 0.9674\n",
      "Epoch 52/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.1010 - accuracy: 0.9692 - val_loss: 0.1172 - val_accuracy: 0.9674\n",
      "Epoch 53/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.1094 - accuracy: 0.9665 - val_loss: 0.1421 - val_accuracy: 0.9674\n",
      "Epoch 54/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.1072 - accuracy: 0.9712 - val_loss: 0.1326 - val_accuracy: 0.9783\n",
      "Epoch 55/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.1042 - accuracy: 0.9618 - val_loss: 0.1355 - val_accuracy: 0.9601\n",
      "Epoch 56/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.1037 - accuracy: 0.9704 - val_loss: 0.0848 - val_accuracy: 0.9746\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0716 - accuracy: 0.9784 - val_loss: 0.1921 - val_accuracy: 0.9638\n",
      "Epoch 58/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.1108 - accuracy: 0.9718 - val_loss: 0.1085 - val_accuracy: 0.9638\n",
      "Epoch 59/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.1103 - accuracy: 0.9679 - val_loss: 0.1080 - val_accuracy: 0.9601\n",
      "Epoch 60/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0866 - accuracy: 0.9742 - val_loss: 0.1025 - val_accuracy: 0.9674\n",
      "Epoch 61/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.0707 - accuracy: 0.9807 - val_loss: 0.0814 - val_accuracy: 0.9710\n",
      "Epoch 62/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0787 - accuracy: 0.9801 - val_loss: 0.0785 - val_accuracy: 0.9674\n",
      "Epoch 63/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0849 - accuracy: 0.9757 - val_loss: 0.0982 - val_accuracy: 0.9746\n",
      "Epoch 64/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0570 - accuracy: 0.9828 - val_loss: 0.1270 - val_accuracy: 0.9601\n",
      "Epoch 65/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0615 - accuracy: 0.9802 - val_loss: 0.0556 - val_accuracy: 0.9819\n",
      "Epoch 66/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0994 - accuracy: 0.9715 - val_loss: 0.0637 - val_accuracy: 0.9783\n",
      "Epoch 67/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0742 - accuracy: 0.9797 - val_loss: 0.1295 - val_accuracy: 0.9601\n",
      "Epoch 68/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0940 - accuracy: 0.9724 - val_loss: 0.0999 - val_accuracy: 0.9710\n",
      "Epoch 69/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.1580 - accuracy: 0.9561 - val_loss: 0.0456 - val_accuracy: 0.9855\n",
      "Epoch 70/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0776 - accuracy: 0.9815 - val_loss: 0.0709 - val_accuracy: 0.9710\n",
      "Epoch 71/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.1269 - accuracy: 0.9664 - val_loss: 0.0751 - val_accuracy: 0.9674\n",
      "Epoch 72/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.1191 - accuracy: 0.9761 - val_loss: 0.0785 - val_accuracy: 0.9746\n",
      "Epoch 73/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0574 - accuracy: 0.9820 - val_loss: 0.0566 - val_accuracy: 0.9783\n",
      "Epoch 74/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0713 - accuracy: 0.9737 - val_loss: 0.0789 - val_accuracy: 0.9746\n",
      "Epoch 75/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.1019 - accuracy: 0.9708 - val_loss: 0.0749 - val_accuracy: 0.9819\n",
      "Epoch 76/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.1131 - accuracy: 0.9652 - val_loss: 0.1226 - val_accuracy: 0.9783\n",
      "Epoch 77/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0622 - accuracy: 0.9775 - val_loss: 0.0366 - val_accuracy: 0.9855\n",
      "Epoch 78/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0973 - accuracy: 0.9760 - val_loss: 0.0894 - val_accuracy: 0.9674\n",
      "Epoch 79/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0770 - accuracy: 0.9748 - val_loss: 0.1072 - val_accuracy: 0.9746\n",
      "Epoch 80/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0622 - accuracy: 0.9773 - val_loss: 0.1229 - val_accuracy: 0.9746\n",
      "Epoch 81/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0763 - accuracy: 0.9728 - val_loss: 0.0436 - val_accuracy: 0.9783\n",
      "Epoch 82/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0716 - accuracy: 0.9783 - val_loss: 0.0861 - val_accuracy: 0.9783\n",
      "Epoch 83/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0664 - accuracy: 0.9792 - val_loss: 0.0757 - val_accuracy: 0.9710\n",
      "Epoch 84/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.0907 - accuracy: 0.9660 - val_loss: 0.1013 - val_accuracy: 0.9710\n",
      "Epoch 85/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0864 - accuracy: 0.9710 - val_loss: 0.0374 - val_accuracy: 0.9819\n",
      "Epoch 86/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0555 - accuracy: 0.9837 - val_loss: 0.0764 - val_accuracy: 0.9674\n",
      "Epoch 87/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.0511 - accuracy: 0.9857 - val_loss: 0.1372 - val_accuracy: 0.9746\n",
      "Epoch 88/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0488 - accuracy: 0.9852 - val_loss: 0.0206 - val_accuracy: 0.9891\n",
      "Epoch 89/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0780 - accuracy: 0.9777 - val_loss: 0.0457 - val_accuracy: 0.9819\n",
      "Epoch 90/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.0629 - accuracy: 0.9887 - val_loss: 0.0666 - val_accuracy: 0.9819\n",
      "Epoch 91/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0260 - accuracy: 0.9910 - val_loss: 0.0357 - val_accuracy: 0.9964\n",
      "Epoch 92/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0686 - accuracy: 0.9831 - val_loss: 0.0220 - val_accuracy: 0.9891\n",
      "Epoch 93/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0493 - accuracy: 0.9838 - val_loss: 0.0839 - val_accuracy: 0.9819\n",
      "Epoch 94/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0669 - accuracy: 0.9833 - val_loss: 0.1348 - val_accuracy: 0.9674\n",
      "Epoch 95/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0854 - accuracy: 0.9713 - val_loss: 0.0571 - val_accuracy: 0.9855\n",
      "Epoch 96/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0898 - accuracy: 0.9804 - val_loss: 0.0519 - val_accuracy: 0.9783\n",
      "Epoch 97/500\n",
      "345/345 [==============================] - 6s 19ms/step - loss: 0.0460 - accuracy: 0.9785 - val_loss: 0.0703 - val_accuracy: 0.9746\n",
      "Epoch 98/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0521 - accuracy: 0.9781 - val_loss: 0.0824 - val_accuracy: 0.9783\n",
      "Epoch 99/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0503 - accuracy: 0.9851 - val_loss: 0.0075 - val_accuracy: 0.9964\n",
      "Epoch 100/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.1148 - accuracy: 0.9757 - val_loss: 0.0643 - val_accuracy: 0.9783\n",
      "Epoch 101/500\n",
      "345/345 [==============================] - 7s 20ms/step - loss: 0.0420 - accuracy: 0.9834 - val_loss: 0.0891 - val_accuracy: 0.9783\n",
      "Epoch 102/500\n",
      "345/345 [==============================] - 7s 20ms/step - loss: 0.1040 - accuracy: 0.9724 - val_loss: 0.0482 - val_accuracy: 0.9855\n",
      "Epoch 103/500\n",
      "345/345 [==============================] - 7s 19ms/step - loss: 0.0663 - accuracy: 0.9857 - val_loss: 0.0716 - val_accuracy: 0.9819\n",
      "Epoch 104/500\n",
      "345/345 [==============================] - 7s 19ms/step - loss: 0.0515 - accuracy: 0.9868 - val_loss: 0.0375 - val_accuracy: 0.9855\n",
      "Epoch 105/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0637 - accuracy: 0.9809 - val_loss: 0.0794 - val_accuracy: 0.9819\n",
      "Epoch 106/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 0.0771 - val_accuracy: 0.9855\n",
      "Epoch 107/500\n",
      "345/345 [==============================] - 7s 19ms/step - loss: 0.0622 - accuracy: 0.9829 - val_loss: 0.0968 - val_accuracy: 0.9855\n",
      "Epoch 108/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0397 - accuracy: 0.9843 - val_loss: 0.0735 - val_accuracy: 0.9928\n",
      "Epoch 109/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0353 - accuracy: 0.9870 - val_loss: 0.0434 - val_accuracy: 0.9855\n",
      "Epoch 110/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0589 - accuracy: 0.9814 - val_loss: 0.0801 - val_accuracy: 0.9783\n",
      "Epoch 111/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0940 - accuracy: 0.9816 - val_loss: 0.0485 - val_accuracy: 0.9819\n",
      "Epoch 112/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0451 - accuracy: 0.9827 - val_loss: 0.0509 - val_accuracy: 0.9819\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0224 - accuracy: 0.9950 - val_loss: 0.1257 - val_accuracy: 0.9674\n",
      "Epoch 114/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0770 - accuracy: 0.9771 - val_loss: 0.0930 - val_accuracy: 0.9746\n",
      "Epoch 115/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0364 - accuracy: 0.9864 - val_loss: 0.0963 - val_accuracy: 0.9783\n",
      "Epoch 116/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0732 - accuracy: 0.9803 - val_loss: 0.0647 - val_accuracy: 0.9819\n",
      "Epoch 117/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0308 - accuracy: 0.9923 - val_loss: 0.0772 - val_accuracy: 0.9855\n",
      "Epoch 118/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0422 - accuracy: 0.9878 - val_loss: 0.0270 - val_accuracy: 0.9891\n",
      "Epoch 119/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.0572 - accuracy: 0.9849 - val_loss: 0.0900 - val_accuracy: 0.9746\n",
      "Epoch 120/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0382 - accuracy: 0.9844 - val_loss: 0.0726 - val_accuracy: 0.9783\n",
      "Epoch 121/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0660 - accuracy: 0.9867 - val_loss: 0.0696 - val_accuracy: 0.9855\n",
      "Epoch 122/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0432 - accuracy: 0.9853 - val_loss: 0.0744 - val_accuracy: 0.9855\n",
      "Epoch 123/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0465 - accuracy: 0.9881 - val_loss: 0.1281 - val_accuracy: 0.9819\n",
      "Epoch 124/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.0781 - val_accuracy: 0.9819\n",
      "Epoch 125/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0373 - accuracy: 0.9868 - val_loss: 0.0413 - val_accuracy: 0.9855\n",
      "Epoch 126/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0368 - accuracy: 0.9913 - val_loss: 0.0418 - val_accuracy: 0.9819\n",
      "Epoch 127/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0520 - accuracy: 0.9840 - val_loss: 0.0406 - val_accuracy: 0.9928\n",
      "Epoch 128/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0693 - accuracy: 0.9823 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0373 - accuracy: 0.9858 - val_loss: 0.0583 - val_accuracy: 0.9928\n",
      "Epoch 130/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0513 - accuracy: 0.9891 - val_loss: 0.0212 - val_accuracy: 0.9928\n",
      "Epoch 131/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0365 - accuracy: 0.9944 - val_loss: 0.0556 - val_accuracy: 0.9964\n",
      "Epoch 132/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0437 - accuracy: 0.9874 - val_loss: 0.0713 - val_accuracy: 0.9819\n",
      "Epoch 133/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.0411 - accuracy: 0.9845 - val_loss: 0.0498 - val_accuracy: 0.9746\n",
      "Epoch 134/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0434 - accuracy: 0.9851 - val_loss: 0.0155 - val_accuracy: 0.9928\n",
      "Epoch 135/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0336 - accuracy: 0.9899 - val_loss: 0.0881 - val_accuracy: 0.9783\n",
      "Epoch 136/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0584 - accuracy: 0.9829 - val_loss: 0.1181 - val_accuracy: 0.9819\n",
      "Epoch 137/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0501 - accuracy: 0.9890 - val_loss: 0.0344 - val_accuracy: 0.9891\n",
      "Epoch 138/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0553 - accuracy: 0.9812 - val_loss: 0.0445 - val_accuracy: 0.9783\n",
      "Epoch 139/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.0369 - accuracy: 0.9907 - val_loss: 0.0503 - val_accuracy: 0.9855\n",
      "Epoch 140/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0515 - accuracy: 0.9883 - val_loss: 0.0277 - val_accuracy: 0.9964\n",
      "Epoch 141/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0485 - accuracy: 0.9830 - val_loss: 0.0349 - val_accuracy: 0.9819\n",
      "Epoch 142/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.0257 - val_accuracy: 0.9855\n",
      "Epoch 143/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0505 - accuracy: 0.9859 - val_loss: 0.0311 - val_accuracy: 0.9855\n",
      "Epoch 144/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0407 - accuracy: 0.9887 - val_loss: 0.0296 - val_accuracy: 0.9928\n",
      "Epoch 145/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0707 - accuracy: 0.9843 - val_loss: 0.0558 - val_accuracy: 0.9855\n",
      "Epoch 146/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0681 - accuracy: 0.9826 - val_loss: 0.0239 - val_accuracy: 0.9964\n",
      "Epoch 147/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.0679 - accuracy: 0.9856 - val_loss: 0.0861 - val_accuracy: 0.9819\n",
      "Epoch 148/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.0430 - accuracy: 0.9904 - val_loss: 0.0466 - val_accuracy: 0.9855\n",
      "Epoch 149/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0750 - accuracy: 0.9802 - val_loss: 0.0949 - val_accuracy: 0.9746\n",
      "Epoch 150/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0380 - accuracy: 0.9917 - val_loss: 0.0373 - val_accuracy: 0.9819\n",
      "Epoch 151/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0392 - accuracy: 0.9876 - val_loss: 0.0404 - val_accuracy: 0.9928\n",
      "Epoch 152/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0503 - accuracy: 0.9835 - val_loss: 0.0465 - val_accuracy: 0.9819\n",
      "Epoch 153/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0339 - accuracy: 0.9915 - val_loss: 0.0298 - val_accuracy: 0.9891\n",
      "Epoch 154/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0243 - accuracy: 0.9955 - val_loss: 0.0755 - val_accuracy: 0.9891\n",
      "Epoch 155/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0256 - accuracy: 0.9925 - val_loss: 0.0384 - val_accuracy: 0.9783\n",
      "Epoch 156/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0521 - accuracy: 0.9857 - val_loss: 0.0311 - val_accuracy: 0.9891\n",
      "Epoch 157/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0265 - accuracy: 0.9891 - val_loss: 0.0362 - val_accuracy: 0.9819\n",
      "Epoch 158/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0402 - accuracy: 0.9903 - val_loss: 0.0202 - val_accuracy: 0.9891\n",
      "Epoch 159/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0513 - accuracy: 0.9861 - val_loss: 0.0330 - val_accuracy: 0.9891\n",
      "Epoch 160/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.0589 - val_accuracy: 0.9819\n",
      "Epoch 161/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0798 - accuracy: 0.9844 - val_loss: 0.0279 - val_accuracy: 0.9855\n",
      "Epoch 162/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0444 - accuracy: 0.9857 - val_loss: 0.0301 - val_accuracy: 0.9928\n",
      "Epoch 163/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0491 - accuracy: 0.9874 - val_loss: 0.0345 - val_accuracy: 0.9855\n",
      "Epoch 164/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0396 - accuracy: 0.9883 - val_loss: 0.0304 - val_accuracy: 0.9928\n",
      "Epoch 165/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0429 - accuracy: 0.9860 - val_loss: 0.0169 - val_accuracy: 0.9928\n",
      "Epoch 166/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0360 - accuracy: 0.9931 - val_loss: 0.0632 - val_accuracy: 0.9819\n",
      "Epoch 167/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0363 - accuracy: 0.9874 - val_loss: 0.0350 - val_accuracy: 0.9928\n",
      "Epoch 168/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0622 - accuracy: 0.9883 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0386 - accuracy: 0.9908 - val_loss: 0.0712 - val_accuracy: 0.9819\n",
      "Epoch 170/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.0551 - accuracy: 0.9845 - val_loss: 0.0300 - val_accuracy: 0.9855\n",
      "Epoch 171/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0278 - accuracy: 0.9877 - val_loss: 0.0754 - val_accuracy: 0.9855\n",
      "Epoch 172/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0562 - accuracy: 0.9856 - val_loss: 0.0783 - val_accuracy: 0.9746\n",
      "Epoch 173/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0359 - accuracy: 0.9944 - val_loss: 0.0483 - val_accuracy: 0.9855\n",
      "Epoch 174/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0403 - accuracy: 0.9840 - val_loss: 0.0654 - val_accuracy: 0.9819\n",
      "Epoch 175/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0374 - accuracy: 0.9835 - val_loss: 7.7594e-04 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "345/345 [==============================] - 5s 15ms/step - loss: 0.0256 - accuracy: 0.9907 - val_loss: 0.0291 - val_accuracy: 0.9891\n",
      "Epoch 177/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0371 - accuracy: 0.9899 - val_loss: 0.1025 - val_accuracy: 0.9819\n",
      "Epoch 178/500\n",
      "345/345 [==============================] - 5s 16ms/step - loss: 0.0348 - accuracy: 0.9888 - val_loss: 0.0145 - val_accuracy: 0.9928\n",
      "Epoch 179/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0327 - accuracy: 0.9854 - val_loss: 0.0622 - val_accuracy: 0.9855\n",
      "Epoch 180/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0569 - accuracy: 0.9825 - val_loss: 0.0100 - val_accuracy: 0.9928\n",
      "Epoch 181/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0417 - accuracy: 0.9909 - val_loss: 0.0474 - val_accuracy: 0.9928\n",
      "Epoch 182/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0547 - accuracy: 0.9879 - val_loss: 0.2022 - val_accuracy: 0.9638\n",
      "Epoch 183/500\n",
      "345/345 [==============================] - 6s 19ms/step - loss: 0.0290 - accuracy: 0.9884 - val_loss: 0.0630 - val_accuracy: 0.9855\n",
      "Epoch 184/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0396 - accuracy: 0.9925 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0668 - accuracy: 0.9855 - val_loss: 0.0441 - val_accuracy: 0.9891\n",
      "Epoch 186/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0418 - accuracy: 0.9879 - val_loss: 0.0179 - val_accuracy: 0.9928\n",
      "Epoch 187/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0459 - accuracy: 0.9908 - val_loss: 0.0259 - val_accuracy: 0.9891\n",
      "Epoch 188/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0618 - accuracy: 0.9854 - val_loss: 0.0527 - val_accuracy: 0.9928\n",
      "Epoch 189/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0478 - accuracy: 0.9868 - val_loss: 0.0251 - val_accuracy: 0.9964\n",
      "Epoch 190/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0622 - accuracy: 0.9897 - val_loss: 0.0692 - val_accuracy: 0.9819\n",
      "Epoch 191/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0586 - accuracy: 0.9810 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0202 - accuracy: 0.9904 - val_loss: 0.0155 - val_accuracy: 0.9928\n",
      "Epoch 193/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0526 - accuracy: 0.9870 - val_loss: 0.0828 - val_accuracy: 0.9891\n",
      "Epoch 194/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0311 - accuracy: 0.9919 - val_loss: 0.0180 - val_accuracy: 0.9928\n",
      "Epoch 195/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0973 - accuracy: 0.9790 - val_loss: 0.0125 - val_accuracy: 0.9964\n",
      "Epoch 196/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0138 - accuracy: 0.9933 - val_loss: 0.0310 - val_accuracy: 0.9891\n",
      "Epoch 197/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0226 - accuracy: 0.9916 - val_loss: 0.0820 - val_accuracy: 0.9819\n",
      "Epoch 198/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0709 - accuracy: 0.9838 - val_loss: 0.0284 - val_accuracy: 0.98550.0717 - ac\n",
      "Epoch 199/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.0900 - val_accuracy: 0.9891\n",
      "Epoch 200/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0639 - accuracy: 0.9815 - val_loss: 0.0890 - val_accuracy: 0.9746\n",
      "Epoch 201/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0339 - accuracy: 0.9910 - val_loss: 0.0171 - val_accuracy: 0.9928\n",
      "Epoch 202/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0312 - accuracy: 0.9937 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0496 - accuracy: 0.9920 - val_loss: 0.0903 - val_accuracy: 0.9819\n",
      "Epoch 204/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0486 - accuracy: 0.9870 - val_loss: 0.0082 - val_accuracy: 0.9964\n",
      "Epoch 205/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0499 - val_accuracy: 0.9855\n",
      "Epoch 206/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0331 - accuracy: 0.9922 - val_loss: 0.0511 - val_accuracy: 0.9783\n",
      "Epoch 207/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0589 - accuracy: 0.9904 - val_loss: 0.0373 - val_accuracy: 0.9891\n",
      "Epoch 208/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0358 - accuracy: 0.9875 - val_loss: 0.0179 - val_accuracy: 0.9928\n",
      "Epoch 209/500\n",
      "345/345 [==============================] - 6s 16ms/step - loss: 0.0750 - accuracy: 0.9888 - val_loss: 0.0138 - val_accuracy: 0.9964\n",
      "Epoch 210/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0256 - accuracy: 0.9934 - val_loss: 0.0655 - val_accuracy: 0.9855\n",
      "Epoch 211/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0419 - accuracy: 0.9906 - val_loss: 0.0539 - val_accuracy: 0.9891\n",
      "Epoch 212/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0383 - accuracy: 0.9919 - val_loss: 0.0350 - val_accuracy: 0.9891\n",
      "Epoch 213/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 0.0287 - val_accuracy: 0.9891\n",
      "Epoch 214/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0400 - accuracy: 0.9915 - val_loss: 0.1012 - val_accuracy: 0.9783\n",
      "Epoch 215/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0199 - accuracy: 0.9917 - val_loss: 0.0331 - val_accuracy: 0.9891\n",
      "Epoch 216/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0673 - accuracy: 0.9863 - val_loss: 0.0336 - val_accuracy: 0.9964\n",
      "Epoch 217/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0466 - accuracy: 0.9880 - val_loss: 0.0346 - val_accuracy: 0.9891\n",
      "Epoch 218/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0273 - accuracy: 0.9970 - val_loss: 0.0255 - val_accuracy: 0.9928\n",
      "Epoch 219/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0413 - accuracy: 0.9889 - val_loss: 0.0826 - val_accuracy: 0.9819\n",
      "Epoch 220/500\n",
      "345/345 [==============================] - 6s 19ms/step - loss: 0.0382 - accuracy: 0.9903 - val_loss: 0.0472 - val_accuracy: 0.9855\n",
      "Epoch 221/500\n",
      "345/345 [==============================] - 7s 20ms/step - loss: 0.0300 - accuracy: 0.9861 - val_loss: 0.0284 - val_accuracy: 0.9928\n",
      "Epoch 222/500\n",
      "345/345 [==============================] - 7s 21ms/step - loss: 0.1124 - accuracy: 0.9859 - val_loss: 0.0440 - val_accuracy: 0.9928\n",
      "Epoch 223/500\n",
      "345/345 [==============================] - 6s 18ms/step - loss: 0.0354 - accuracy: 0.9918 - val_loss: 0.0276 - val_accuracy: 0.9891\n",
      "Epoch 224/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0422 - accuracy: 0.9868 - val_loss: 0.0164 - val_accuracy: 0.9964\n",
      "Epoch 225/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0267 - accuracy: 0.9919 - val_loss: 0.0530 - val_accuracy: 0.9819\n",
      "Epoch 226/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0326 - accuracy: 0.9912 - val_loss: 0.0278 - val_accuracy: 0.9891\n",
      "Epoch 227/500\n",
      "345/345 [==============================] - 5s 14ms/step - loss: 0.0419 - accuracy: 0.9895 - val_loss: 0.0117 - val_accuracy: 0.9928\n",
      "Epoch 228/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0211 - accuracy: 0.9962 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "345/345 [==============================] - 5s 13ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.0187 - val_accuracy: 0.9964\n",
      "Epoch 230/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0206 - accuracy: 0.9944 - val_loss: 0.0365 - val_accuracy: 0.9819\n",
      "Epoch 231/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0187 - val_accuracy: 0.9891\n",
      "Epoch 232/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0212 - accuracy: 0.9968 - val_loss: 0.0585 - val_accuracy: 0.9855\n",
      "Epoch 233/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.0266 - val_accuracy: 0.9964\n",
      "Epoch 234/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0381 - accuracy: 0.9920 - val_loss: 0.0245 - val_accuracy: 0.9928\n",
      "Epoch 235/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0068 - accuracy: 0.9956 - val_loss: 0.0707 - val_accuracy: 0.9819\n",
      "Epoch 236/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0376 - accuracy: 0.9890 - val_loss: 0.0251 - val_accuracy: 0.9928\n",
      "Epoch 237/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0552 - accuracy: 0.9881 - val_loss: 0.0518 - val_accuracy: 0.9783\n",
      "Epoch 238/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0244 - accuracy: 0.9929 - val_loss: 0.0102 - val_accuracy: 0.9928\n",
      "Epoch 239/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0666 - val_accuracy: 0.9855\n",
      "Epoch 240/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0259 - accuracy: 0.9901 - val_loss: 0.0355 - val_accuracy: 0.9928\n",
      "Epoch 241/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0431 - accuracy: 0.9840 - val_loss: 0.0149 - val_accuracy: 0.9928\n",
      "Epoch 242/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.0258 - val_accuracy: 0.9964\n",
      "Epoch 243/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0503 - accuracy: 0.9902 - val_loss: 0.0103 - val_accuracy: 0.9964\n",
      "Epoch 244/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0222 - accuracy: 0.9918 - val_loss: 0.0320 - val_accuracy: 0.9855\n",
      "Epoch 245/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0194 - accuracy: 0.9959 - val_loss: 0.0599 - val_accuracy: 0.9891\n",
      "Epoch 246/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0280 - accuracy: 0.9878 - val_loss: 0.0486 - val_accuracy: 0.9783\n",
      "Epoch 247/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.0206 - val_accuracy: 0.9964\n",
      "Epoch 248/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0139 - accuracy: 0.9943 - val_loss: 0.0085 - val_accuracy: 0.9964\n",
      "Epoch 249/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0514 - accuracy: 0.9908 - val_loss: 0.0426 - val_accuracy: 0.9891\n",
      "Epoch 250/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0293 - accuracy: 0.9962 - val_loss: 0.0348 - val_accuracy: 0.9819\n",
      "Epoch 251/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0392 - accuracy: 0.9870 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0318 - accuracy: 0.9877 - val_loss: 0.0655 - val_accuracy: 0.9891\n",
      "Epoch 253/500\n",
      "345/345 [==============================] - 5s 13ms/step - loss: 0.0177 - accuracy: 0.9955 - val_loss: 0.0238 - val_accuracy: 0.9964\n",
      "Epoch 254/500\n",
      "345/345 [==============================] - 5s 13ms/step - loss: 0.0247 - accuracy: 0.9900 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "345/345 [==============================] - 5s 14ms/step - loss: 0.0484 - accuracy: 0.9875 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 0.0151 - val_accuracy: 0.9891\n",
      "Epoch 258/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0315 - accuracy: 0.9908 - val_loss: 0.0523 - val_accuracy: 0.9855\n",
      "Epoch 259/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0210 - accuracy: 0.9946 - val_loss: 0.0221 - val_accuracy: 0.9928\n",
      "Epoch 260/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0343 - accuracy: 0.9879 - val_loss: 0.0273 - val_accuracy: 0.9891\n",
      "Epoch 261/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0487 - val_accuracy: 0.9855\n",
      "Epoch 262/500\n",
      "345/345 [==============================] - 5s 13ms/step - loss: 0.0284 - accuracy: 0.9926 - val_loss: 0.0263 - val_accuracy: 0.9928\n",
      "Epoch 263/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.0551 - val_accuracy: 0.9928\n",
      "Epoch 264/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0171 - val_accuracy: 0.9964\n",
      "Epoch 265/500\n",
      "345/345 [==============================] - 5s 14ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0376 - val_accuracy: 0.9891\n",
      "Epoch 266/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0266 - accuracy: 0.9959 - val_loss: 0.0195 - val_accuracy: 0.9928\n",
      "Epoch 267/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0258 - accuracy: 0.9927 - val_loss: 0.0366 - val_accuracy: 0.9928\n",
      "Epoch 268/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.0257 - val_accuracy: 0.9891\n",
      "Epoch 269/500\n",
      "345/345 [==============================] - 5s 13ms/step - loss: 0.0416 - accuracy: 0.9910 - val_loss: 0.0236 - val_accuracy: 0.9855\n",
      "Epoch 270/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0440 - accuracy: 0.9891 - val_loss: 0.0737 - val_accuracy: 0.9819\n",
      "Epoch 271/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0256 - accuracy: 0.9934 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0495 - accuracy: 0.9872 - val_loss: 0.0307 - val_accuracy: 0.9964\n",
      "Epoch 273/500\n",
      "345/345 [==============================] - 5s 13ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0206 - accuracy: 0.9871 - val_loss: 0.0298 - val_accuracy: 0.9891\n",
      "Epoch 275/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0545 - accuracy: 0.9898 - val_loss: 0.0527 - val_accuracy: 0.9855\n",
      "Epoch 276/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0361 - accuracy: 0.9875 - val_loss: 0.0408 - val_accuracy: 0.9855\n",
      "Epoch 277/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0063 - val_accuracy: 0.9964\n",
      "Epoch 278/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0452 - accuracy: 0.9928 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0297 - accuracy: 0.9958 - val_loss: 0.0180 - val_accuracy: 0.9964\n",
      "Epoch 280/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0249 - accuracy: 0.9932 - val_loss: 0.0489 - val_accuracy: 0.9855\n",
      "Epoch 281/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0493 - accuracy: 0.9838 - val_loss: 0.0638 - val_accuracy: 0.9855\n",
      "Epoch 282/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.1005 - accuracy: 0.9877 - val_loss: 0.0603 - val_accuracy: 0.9891\n",
      "Epoch 283/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0342 - accuracy: 0.9906 - val_loss: 0.0781 - val_accuracy: 0.9783\n",
      "Epoch 284/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0243 - accuracy: 0.9953 - val_loss: 0.0056 - val_accuracy: 0.9964\n",
      "Epoch 285/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.0123 - val_accuracy: 0.9928\n",
      "Epoch 286/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 0.0586 - val_accuracy: 0.9855\n",
      "Epoch 287/500\n",
      "345/345 [==============================] - 5s 13ms/step - loss: 0.0286 - accuracy: 0.9935 - val_loss: 0.0446 - val_accuracy: 0.9819\n",
      "Epoch 288/500\n",
      "345/345 [==============================] - 5s 14ms/step - loss: 0.0533 - accuracy: 0.9908 - val_loss: 0.0124 - val_accuracy: 0.9928\n",
      "Epoch 289/500\n",
      "345/345 [==============================] - 6s 17ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.0375 - val_accuracy: 0.9928\n",
      "Epoch 290/500\n",
      "345/345 [==============================] - 5s 14ms/step - loss: 0.0390 - accuracy: 0.9936 - val_loss: 0.0443 - val_accuracy: 0.9891\n",
      "Epoch 291/500\n",
      "345/345 [==============================] - 5s 14ms/step - loss: 0.0458 - accuracy: 0.9912 - val_loss: 0.0429 - val_accuracy: 0.9891\n",
      "Epoch 292/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0486 - accuracy: 0.9915 - val_loss: 0.0316 - val_accuracy: 0.9964\n",
      "Epoch 293/500\n",
      "345/345 [==============================] - 4s 11ms/step - loss: 0.0441 - accuracy: 0.9908 - val_loss: 0.0101 - val_accuracy: 0.9964\n",
      "Epoch 294/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0271 - accuracy: 0.9931 - val_loss: 0.0095 - val_accuracy: 0.9964\n",
      "Epoch 295/500\n",
      "345/345 [==============================] - 4s 11ms/step - loss: 0.0147 - accuracy: 0.9938 - val_loss: 0.0248 - val_accuracy: 0.9891\n",
      "Epoch 296/500\n",
      "345/345 [==============================] - 4s 11ms/step - loss: 0.0273 - accuracy: 0.9924 - val_loss: 0.0273 - val_accuracy: 0.9891\n",
      "Epoch 297/500\n",
      "345/345 [==============================] - 4s 11ms/step - loss: 0.0411 - accuracy: 0.9918 - val_loss: 0.0245 - val_accuracy: 0.9964\n",
      "Epoch 298/500\n",
      "345/345 [==============================] - 4s 11ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.0069 - val_accuracy: 0.9964\n",
      "Epoch 299/500\n",
      "345/345 [==============================] - 4s 11ms/step - loss: 0.0173 - accuracy: 0.9966 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "345/345 [==============================] - 4s 11ms/step - loss: 0.0512 - accuracy: 0.9922 - val_loss: 0.0543 - val_accuracy: 0.9964\n",
      "Epoch 301/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 2.8297e-04 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0317 - accuracy: 0.9946 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "345/345 [==============================] - 4s 11ms/step - loss: 0.0197 - accuracy: 0.9922 - val_loss: 0.0396 - val_accuracy: 0.9964\n",
      "Epoch 304/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0512 - accuracy: 0.9886 - val_loss: 0.0135 - val_accuracy: 0.9964\n",
      "Epoch 305/500\n",
      "345/345 [==============================] - 4s 11ms/step - loss: 0.0084 - accuracy: 0.9964 - val_loss: 0.0133 - val_accuracy: 0.9928\n",
      "Epoch 306/500\n",
      "345/345 [==============================] - 4s 11ms/step - loss: 0.0172 - accuracy: 0.9934 - val_loss: 0.0301 - val_accuracy: 0.9819\n",
      "Epoch 307/500\n",
      "345/345 [==============================] - 4s 11ms/step - loss: 0.0293 - accuracy: 0.9903 - val_loss: 0.0096 - val_accuracy: 0.9964\n",
      "Epoch 308/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0165 - accuracy: 0.9931 - val_loss: 0.0119 - val_accuracy: 0.9964\n",
      "Epoch 309/500\n",
      "345/345 [==============================] - 4s 13ms/step - loss: 0.0270 - accuracy: 0.9929 - val_loss: 0.0150 - val_accuracy: 0.9964\n",
      "Epoch 310/500\n",
      "345/345 [==============================] - 4s 12ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0143 - val_accuracy: 0.9964\n",
      "Epoch 311/500\n",
      "345/345 [==============================] - 3s 10ms/step - loss: 0.0327 - accuracy: 0.9932 - val_loss: 0.0387 - val_accuracy: 0.9891\n",
      "Epoch 312/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0386 - accuracy: 0.9943 - val_loss: 0.0073 - val_accuracy: 0.9964\n",
      "Epoch 313/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0380 - accuracy: 0.9910 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0400 - accuracy: 0.9894 - val_loss: 0.0118 - val_accuracy: 0.9964\n",
      "Epoch 315/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 0.0198 - val_accuracy: 0.9928\n",
      "Epoch 316/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0231 - accuracy: 0.9959 - val_loss: 0.0132 - val_accuracy: 0.9964\n",
      "Epoch 317/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.0312 - val_accuracy: 0.9855\n",
      "Epoch 318/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.0090 - val_accuracy: 0.9964\n",
      "Epoch 319/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0383 - accuracy: 0.9921 - val_loss: 0.0207 - val_accuracy: 0.9928\n",
      "Epoch 320/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0241 - accuracy: 0.9911 - val_loss: 0.0173 - val_accuracy: 0.9928\n",
      "Epoch 321/500\n",
      "345/345 [==============================] - 3s 9ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 0.0988 - val_accuracy: 0.9891\n",
      "Epoch 322/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.0588 - val_accuracy: 0.9891\n",
      "Epoch 323/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 0.0220 - val_accuracy: 0.9928\n",
      "Epoch 324/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0280 - accuracy: 0.9931 - val_loss: 0.0338 - val_accuracy: 0.9928\n",
      "Epoch 325/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0087 - accuracy: 0.9967 - val_loss: 0.0474 - val_accuracy: 0.9891\n",
      "Epoch 326/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0168 - accuracy: 0.9967 - val_loss: 0.0049 - val_accuracy: 0.9964\n",
      "Epoch 327/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0320 - accuracy: 0.9968 - val_loss: 0.0489 - val_accuracy: 0.9855\n",
      "Epoch 328/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0763 - accuracy: 0.9907 - val_loss: 0.0103 - val_accuracy: 0.9964\n",
      "Epoch 329/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0189 - val_accuracy: 0.9964\n",
      "Epoch 330/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0321 - accuracy: 0.9913 - val_loss: 0.0268 - val_accuracy: 0.9964\n",
      "Epoch 331/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 5.3933e-05 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0494 - accuracy: 0.9878 - val_loss: 0.0238 - val_accuracy: 0.9964\n",
      "Epoch 333/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0368 - accuracy: 0.9897 - val_loss: 0.0197 - val_accuracy: 0.9928\n",
      "Epoch 334/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0279 - accuracy: 0.9956 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0327 - val_accuracy: 0.9928\n",
      "Epoch 337/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.0132 - val_accuracy: 0.9928\n",
      "Epoch 338/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.0517 - val_accuracy: 0.9928\n",
      "Epoch 339/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0293 - val_accuracy: 0.9928\n",
      "Epoch 340/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0250 - accuracy: 0.9946 - val_loss: 0.0168 - val_accuracy: 0.9855\n",
      "Epoch 341/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0254 - accuracy: 0.9940 - val_loss: 0.0105 - val_accuracy: 0.9964\n",
      "Epoch 342/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0385 - accuracy: 0.9913 - val_loss: 0.0863 - val_accuracy: 0.9819\n",
      "Epoch 343/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0192 - accuracy: 0.9961 - val_loss: 0.0056 - val_accuracy: 0.9964\n",
      "Epoch 344/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0274 - accuracy: 0.9936 - val_loss: 0.0411 - val_accuracy: 0.9855\n",
      "Epoch 345/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0154 - accuracy: 0.9945 - val_loss: 0.0372 - val_accuracy: 0.9891\n",
      "Epoch 346/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0370 - accuracy: 0.9938 - val_loss: 0.0062 - val_accuracy: 0.9964\n",
      "Epoch 347/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0458 - accuracy: 0.9916 - val_loss: 0.0465 - val_accuracy: 0.9819\n",
      "Epoch 348/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0047 - val_accuracy: 0.9964\n",
      "Epoch 349/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0326 - accuracy: 0.9914 - val_loss: 0.0635 - val_accuracy: 0.9855\n",
      "Epoch 350/500\n",
      "345/345 [==============================] - 3s 9ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0221 - val_accuracy: 0.9964\n",
      "Epoch 351/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0471 - accuracy: 0.9920 - val_loss: 0.0406 - val_accuracy: 0.9891\n",
      "Epoch 352/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0186 - accuracy: 0.9974 - val_loss: 0.0167 - val_accuracy: 0.9964\n",
      "Epoch 353/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0285 - accuracy: 0.9928 - val_loss: 0.0262 - val_accuracy: 0.9928\n",
      "Epoch 354/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0614 - accuracy: 0.9889 - val_loss: 0.0104 - val_accuracy: 0.9928\n",
      "Epoch 355/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0073 - val_accuracy: 0.9964\n",
      "Epoch 356/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0124 - accuracy: 0.9948 - val_loss: 9.1652e-04 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0186 - val_accuracy: 0.9928\n",
      "Epoch 358/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0351 - accuracy: 0.9947 - val_loss: 0.0146 - val_accuracy: 0.9964\n",
      "Epoch 359/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.0363 - val_accuracy: 0.9928\n",
      "Epoch 360/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0166 - accuracy: 0.9929 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0482 - val_accuracy: 0.9891\n",
      "Epoch 362/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0378 - accuracy: 0.9942 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0495 - val_accuracy: 0.9891\n",
      "Epoch 364/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0407 - accuracy: 0.9941 - val_loss: 0.0407 - val_accuracy: 0.9928\n",
      "Epoch 365/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0309 - accuracy: 0.9921 - val_loss: 0.0894 - val_accuracy: 0.9819\n",
      "Epoch 366/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0164 - accuracy: 0.9976 - val_loss: 0.0104 - val_accuracy: 0.9964\n",
      "Epoch 367/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.0351 - val_accuracy: 0.9928\n",
      "Epoch 368/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0222 - accuracy: 0.9893 - val_loss: 0.0179 - val_accuracy: 0.9964\n",
      "Epoch 369/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.0888 - val_accuracy: 0.9891\n",
      "Epoch 370/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.0427 - val_accuracy: 0.9928\n",
      "Epoch 371/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0075 - accuracy: 0.9963 - val_loss: 0.1181 - val_accuracy: 0.9819\n",
      "Epoch 372/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0695 - accuracy: 0.9906 - val_loss: 0.0579 - val_accuracy: 0.9891\n",
      "Epoch 373/500\n",
      "345/345 [==============================] - 3s 9ms/step - loss: 0.0298 - accuracy: 0.9940 - val_loss: 0.0274 - val_accuracy: 0.9928\n",
      "Epoch 374/500\n",
      "345/345 [==============================] - 3s 9ms/step - loss: 0.0139 - accuracy: 0.9930 - val_loss: 0.0498 - val_accuracy: 0.9855\n",
      "Epoch 375/500\n",
      "345/345 [==============================] - 3s 9ms/step - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.0629 - val_accuracy: 0.9891\n",
      "Epoch 376/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0047 - accuracy: 0.9977 - val_loss: 0.0174 - val_accuracy: 0.9928\n",
      "Epoch 377/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0554 - accuracy: 0.9901 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0384 - accuracy: 0.9912 - val_loss: 0.0420 - val_accuracy: 0.9928\n",
      "Epoch 379/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0205 - accuracy: 0.9971 - val_loss: 0.0396 - val_accuracy: 0.9855\n",
      "Epoch 380/500\n",
      "345/345 [==============================] - 3s 9ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.0225 - val_accuracy: 0.9928\n",
      "Epoch 381/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0126 - accuracy: 0.9987 - val_loss: 0.0204 - val_accuracy: 0.9964\n",
      "Epoch 382/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.1044 - val_accuracy: 0.9855\n",
      "Epoch 383/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0577 - accuracy: 0.9946 - val_loss: 0.0223 - val_accuracy: 0.9891\n",
      "Epoch 384/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0190 - accuracy: 0.9959 - val_loss: 0.0080 - val_accuracy: 0.9964\n",
      "Epoch 385/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0142 - accuracy: 0.9941 - val_loss: 0.0566 - val_accuracy: 0.9964\n",
      "Epoch 386/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.0702 - val_accuracy: 0.9783\n",
      "Epoch 387/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 0.0047 - val_accuracy: 0.9964\n",
      "Epoch 389/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0213 - accuracy: 0.9901 - val_loss: 0.0781 - val_accuracy: 0.9891\n",
      "Epoch 390/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0192 - accuracy: 0.9968 - val_loss: 0.0158 - val_accuracy: 0.9928\n",
      "Epoch 391/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.0340 - val_accuracy: 0.9855\n",
      "Epoch 392/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0176 - accuracy: 0.9919 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0107 - accuracy: 0.9953 - val_loss: 0.0144 - val_accuracy: 0.9964\n",
      "Epoch 394/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0206 - accuracy: 0.9910 - val_loss: 0.0548 - val_accuracy: 0.9928\n",
      "Epoch 395/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0473 - accuracy: 0.9895 - val_loss: 0.0097 - val_accuracy: 0.9964\n",
      "Epoch 396/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0455 - val_accuracy: 0.9928\n",
      "Epoch 397/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0264 - accuracy: 0.9939 - val_loss: 0.0832 - val_accuracy: 0.9891\n",
      "Epoch 398/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0257 - accuracy: 0.9974 - val_loss: 4.2569e-04 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0119 - accuracy: 0.9975 - val_loss: 0.0087 - val_accuracy: 0.9964\n",
      "Epoch 400/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0405 - accuracy: 0.9885 - val_loss: 0.0295 - val_accuracy: 0.9928\n",
      "Epoch 401/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0700 - accuracy: 0.9894 - val_loss: 0.0097 - val_accuracy: 0.9964\n",
      "Epoch 402/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0119 - accuracy: 0.9936 - val_loss: 8.4708e-04 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0353 - val_accuracy: 0.9928\n",
      "Epoch 404/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0377 - accuracy: 0.9933 - val_loss: 0.0072 - val_accuracy: 0.9964\n",
      "Epoch 405/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 0.0458 - val_accuracy: 0.9928\n",
      "Epoch 406/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 2.0791e-05 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0154 - accuracy: 0.9976 - val_loss: 0.0087 - val_accuracy: 0.9964\n",
      "Epoch 408/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0337 - accuracy: 0.9919 - val_loss: 0.0064 - val_accuracy: 0.9964\n",
      "Epoch 409/500\n",
      "345/345 [==============================] - 3s 9ms/step - loss: 0.0364 - accuracy: 0.9909 - val_loss: 0.0342 - val_accuracy: 0.9891\n",
      "Epoch 410/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 8.7289e-04 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0066 - accuracy: 0.9973 - val_loss: 0.0601 - val_accuracy: 0.9891\n",
      "Epoch 412/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0196 - accuracy: 0.9894 - val_loss: 0.0152 - val_accuracy: 0.9928\n",
      "Epoch 413/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0109 - accuracy: 0.9981 - val_loss: 0.0247 - val_accuracy: 0.9891\n",
      "Epoch 414/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0301 - val_accuracy: 0.9964\n",
      "Epoch 415/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0111 - val_accuracy: 0.9964\n",
      "Epoch 416/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0258 - accuracy: 0.9941 - val_loss: 0.0191 - val_accuracy: 0.9964\n",
      "Epoch 417/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0406 - accuracy: 0.9933 - val_loss: 4.6071e-04 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.0243 - val_accuracy: 0.9928\n",
      "Epoch 419/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0176 - accuracy: 0.9956 - val_loss: 0.0070 - val_accuracy: 0.9964\n",
      "Epoch 420/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0219 - accuracy: 0.9982 - val_loss: 0.0069 - val_accuracy: 0.9964\n",
      "Epoch 421/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0312 - accuracy: 0.9945 - val_loss: 8.2860e-04 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 6.7616e-04 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.1316 - val_accuracy: 0.9891\n",
      "Epoch 424/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0176 - accuracy: 0.9974 - val_loss: 0.0161 - val_accuracy: 0.9928\n",
      "Epoch 425/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0248 - accuracy: 0.9944 - val_loss: 8.8273e-05 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0156 - accuracy: 0.9933 - val_loss: 0.0210 - val_accuracy: 0.9964\n",
      "Epoch 427/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.0459 - val_accuracy: 0.9928\n",
      "Epoch 428/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0817 - accuracy: 0.9860 - val_loss: 0.0348 - val_accuracy: 0.9928\n",
      "Epoch 429/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0268 - accuracy: 0.9936 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.0074 - val_accuracy: 0.9964\n",
      "Epoch 431/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.0696 - val_accuracy: 0.9928\n",
      "Epoch 432/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0090 - accuracy: 0.9950 - val_loss: 0.0100 - val_accuracy: 0.9928\n",
      "Epoch 433/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0317 - accuracy: 0.9922 - val_loss: 0.0048 - val_accuracy: 0.9964\n",
      "Epoch 434/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0035 - accuracy: 0.9996 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0268 - accuracy: 0.9933 - val_loss: 0.0277 - val_accuracy: 0.9891\n",
      "Epoch 436/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0179 - accuracy: 0.9971 - val_loss: 0.0102 - val_accuracy: 0.9964\n",
      "Epoch 437/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0168 - accuracy: 0.9956 - val_loss: 0.0898 - val_accuracy: 0.9928\n",
      "Epoch 438/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0052 - accuracy: 0.9978 - val_loss: 2.9681e-04 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0223 - accuracy: 0.9934 - val_loss: 0.0036 - val_accuracy: 0.9964\n",
      "Epoch 440/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0267 - accuracy: 0.9982 - val_loss: 0.0173 - val_accuracy: 0.9928\n",
      "Epoch 441/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0211 - accuracy: 0.9965 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.0187 - val_accuracy: 0.9928\n",
      "Epoch 443/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0306 - accuracy: 0.9936 - val_loss: 0.0637 - val_accuracy: 0.9891\n",
      "Epoch 444/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 6.9851e-04 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0214 - val_accuracy: 0.9928\n",
      "Epoch 446/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0096 - accuracy: 0.9990 - val_loss: 0.0687 - val_accuracy: 0.9855\n",
      "Epoch 447/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.0211 - val_accuracy: 0.9928\n",
      "Epoch 448/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0345 - accuracy: 0.9955 - val_loss: 0.0677 - val_accuracy: 0.9928\n",
      "Epoch 449/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0310 - accuracy: 0.9941 - val_loss: 0.0124 - val_accuracy: 0.9964\n",
      "Epoch 450/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0232 - accuracy: 0.9965 - val_loss: 0.0159 - val_accuracy: 0.9928\n",
      "Epoch 451/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0098 - accuracy: 0.9958 - val_loss: 1.2155e-04 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0101 - accuracy: 0.9984 - val_loss: 0.0460 - val_accuracy: 0.9928\n",
      "Epoch 453/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0187 - accuracy: 0.9975 - val_loss: 0.0122 - val_accuracy: 0.9891\n",
      "Epoch 454/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0440 - accuracy: 0.9942 - val_loss: 0.0306 - val_accuracy: 0.9964\n",
      "Epoch 455/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.0273 - val_accuracy: 0.9928\n",
      "Epoch 456/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.0064 - val_accuracy: 0.9964\n",
      "Epoch 457/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0135 - accuracy: 0.9991 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0107 - val_accuracy: 0.9964\n",
      "Epoch 459/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0328 - accuracy: 0.9932 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0185 - accuracy: 0.9971 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0410 - accuracy: 0.9961 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 0.0391 - val_accuracy: 0.9964\n",
      "Epoch 463/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.0035 - val_accuracy: 0.9964\n",
      "Epoch 464/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0111 - val_accuracy: 0.9964\n",
      "Epoch 465/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 1.7267e-04 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0193 - accuracy: 0.9963 - val_loss: 0.0282 - val_accuracy: 0.9928\n",
      "Epoch 468/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0292 - accuracy: 0.9921 - val_loss: 5.5281e-04 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0253 - accuracy: 0.9961 - val_loss: 0.0386 - val_accuracy: 0.9964\n",
      "Epoch 470/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0151 - accuracy: 0.9985 - val_loss: 0.0468 - val_accuracy: 0.9819\n",
      "Epoch 472/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0304 - accuracy: 0.9924 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0064 - accuracy: 0.9956 - val_loss: 0.0085 - val_accuracy: 0.9964\n",
      "Epoch 474/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0265 - accuracy: 0.9927 - val_loss: 0.0679 - val_accuracy: 0.9891\n",
      "Epoch 475/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0327 - accuracy: 0.9936 - val_loss: 0.0265 - val_accuracy: 0.9928\n",
      "Epoch 476/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.0240 - val_accuracy: 0.9928\n",
      "Epoch 477/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.0217 - val_accuracy: 0.9964\n",
      "Epoch 478/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0298 - accuracy: 0.9942 - val_loss: 0.0108 - val_accuracy: 0.9964\n",
      "Epoch 479/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0081 - accuracy: 0.9967 - val_loss: 6.2650e-05 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0315 - accuracy: 0.9921 - val_loss: 5.6607e-05 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0191 - accuracy: 0.9966 - val_loss: 0.0661 - val_accuracy: 0.9891\n",
      "Epoch 482/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0159 - accuracy: 0.9959 - val_loss: 8.2411e-04 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0084 - val_accuracy: 0.9928\n",
      "Epoch 484/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0207 - val_accuracy: 0.9964\n",
      "Epoch 486/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0248 - accuracy: 0.9932 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0839 - val_accuracy: 0.9891\n",
      "Epoch 488/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0054 - val_accuracy: 0.9964\n",
      "Epoch 489/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0199 - accuracy: 0.9965 - val_loss: 0.0162 - val_accuracy: 0.9964\n",
      "Epoch 490/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "345/345 [==============================] - 2s 7ms/step - loss: 0.0403 - accuracy: 0.9941 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0250 - accuracy: 0.9958 - val_loss: 0.0144 - val_accuracy: 0.9964\n",
      "Epoch 493/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0128 - accuracy: 0.9980 - val_loss: 0.0277 - val_accuracy: 0.9964\n",
      "Epoch 494/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0175 - accuracy: 0.9902 - val_loss: 0.0096 - val_accuracy: 0.9964\n",
      "Epoch 495/500\n",
      "345/345 [==============================] - 3s 8ms/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.0119 - val_accuracy: 0.9964\n",
      "Epoch 496/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0171 - val_accuracy: 0.9964\n",
      "Epoch 498/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0204 - accuracy: 0.9973 - val_loss: 0.0106 - val_accuracy: 0.9964\n",
      "Epoch 499/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.0205 - val_accuracy: 0.9964\n",
      "Epoch 500/500\n",
      "345/345 [==============================] - 3s 7ms/step - loss: 0.0191 - accuracy: 0.9974 - val_loss: 0.0538 - val_accuracy: 0.9928\n"
     ]
    }
   ],
   "source": [
    "Batch_Size = 4\n",
    "Shift_Range = 1\n",
    "Brightness_Range = 0.3\n",
    "Rotation_Angle = 10\n",
    "ZoomRange = 0.4\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], \n",
    "                             height_shift_range=[-Shift_Range,Shift_Range],\n",
    "                             brightness_range=[1-Brightness_Range,1+Brightness_Range],\n",
    "                             zoom_range=[1-ZoomRange, 1+ZoomRange],\n",
    "                             rotation_range=Rotation_Angle)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, epochs = Epoch_Anz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learing result\n",
    " \n",
    "* Visualization of the training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "plt.semilogy(history.history['loss'])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model by hand\n",
    "\n",
    "* The following code uses the trained model to check the deviation for each picture.\n",
    "* x-axis walks through each pixel, y-axis shows the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Input_dir='ziffer_sortiert_resize'\n",
    "subdir = [\"NaN\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "res = []\n",
    "\n",
    "for aktsubdir in subdir:\n",
    "    files = glob.glob(Input_dir + '/' + aktsubdir + '\\*.jpg')\n",
    "    if aktsubdir == \"NaN\":\n",
    "        zw1 = -1\n",
    "    else:\n",
    "        zw1 = int(aktsubdir)\n",
    "    for aktfile in files:\n",
    "        test_image = Image.open(aktfile)\n",
    "        test_image = np.array(test_image, dtype=\"float32\")\n",
    "        img = np.reshape(test_image,[1,32,20,3])\n",
    "        classes = np.argmax(model.predict(img), axis=-1)\n",
    "        classes = classes[0]\n",
    "        if classes == 10: \n",
    "            classes = -1\n",
    "        zw2 = classes\n",
    "        zw3 = zw2 - zw1\n",
    "        res.append(np.array([zw1, zw2, zw3]))\n",
    "\n",
    "res = np.asarray(res)\n",
    "\n",
    "\n",
    "plt.plot(res[:,0])\n",
    "plt.plot(res[:,1])\n",
    "plt.title('Result')\n",
    "plt.ylabel('Digital Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['real','model'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Save the model to the file with the \"h5\" file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Muell\\AppData\\Local\\Temp\\tmpqsiyyjyv\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1303008"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileName = TFliteNamingAndVersion\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Muell\\AppData\\Local\\Temp\\tmpywhrltnt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Muell\\AppData\\Local\\Temp\\tmpywhrltnt\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "338112"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileName = TFliteNamingAndVersion + \"q\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def representative_dataset():\n",
    "    for _ in range(500):\n",
    "      data = np.random.rand(1, 32, 20, 3) * 255\n",
    "      yield [data.astype(np.float32)]\n",
    "        \n",
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter2.representative_dataset = representative_dataset\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter2.convert()\n",
    "\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check each image for expected and deviation\n",
    "* setting the switch \"only_deviation = true\" will only print the images for which the classification and the CNN-result deviates\n",
    "\n",
    "The output contains the following information:\n",
    "\n",
    "| Filename      | Expected Category           | Predicted Category        |\n",
    "|------------- |:-----------------------------:|--------------|\n",
    "| ziffer_sortiert_resize_NaN/5\\Ziffer_4_0034.jpg | 4  | -1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ziffer_sortiert_resize/3\\1_ht4_20210627-124615.jpg 3 NaN\n"
     ]
    }
   ],
   "source": [
    "Input_dir='ziffer_sortiert_resize'\n",
    "only_deviation = True\n",
    "\n",
    "subdir = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"NaN\"]\n",
    "\n",
    "for aktsubdir in subdir:\n",
    "    files = glob.glob(Input_dir + '/' + aktsubdir + '\\*.jpg')\n",
    "    expected_class = aktsubdir\n",
    "    for aktfile in files:\n",
    "        test_image = Image.open(aktfile)\n",
    "        test_image = np.array(test_image, dtype=\"float32\")\n",
    "        img = np.reshape(test_image,[1,32,20,3])\n",
    "        classes = np.argmax(model.predict(img), axis=-1)\n",
    "        classes = classes[0]\n",
    "        if classes == 10: \n",
    "            classes = \"NaN\"\n",
    "        if only_deviation == True:\n",
    "            if str(classes) != str(expected_class):\n",
    "                print(aktfile + \" \" + aktsubdir +  \" \" + str(classes))\n",
    "        else:\n",
    "            print(aktfile + \" \" + aktsubdir +  \" \" + str(classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the images shows, that this are border line images, which can be interpreted as a good digit or a faulty one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
