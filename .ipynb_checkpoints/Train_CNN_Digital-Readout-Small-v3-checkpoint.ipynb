{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Training\n",
    "\n",
    "Target of this code is to train a CNN network to classify images of a digital readout to the digits 0 to 9. Additionally a category \"NaN\" is introduced, to mark images that are not amibiguous.\n",
    "\n",
    "### Preparing the training\n",
    "* First all libraries are loaded\n",
    "    * It is assumed, that they are installed during the Python setup\n",
    "* matplotlib is set to print the output inline in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########### Basic Parameters for Running: ################################\n",
    "    \n",
    "TFliteNamingAndVersion = \"dig1010s3\"   # Used for tflite Filename\n",
    "Training_Percentage = 0.0              # 0.0 = Use all Images for Training\n",
    "Epoch_Anz = 500\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, InputLayer, Conv2D, MaxPool2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import History \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image \n",
    "\n",
    "loss_ges = np.array([])\n",
    "val_loss_ges = np.array([])\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "* The data is expected in the \"Input_dir\"\n",
    "* Inside subdirectories are expected from -1, 0, 1, ... 9 in which the pictures are sorted according to their values (=category)\n",
    "* Picture size must be 20x32 with 3 color channels (RGB)\n",
    "* The filename can be arbitrary\n",
    "\n",
    "* The images are stored in the x_data[]\n",
    "* The expected category for each image in the corresponding y_data[]\n",
    "\n",
    "* The last step is a shuffle (from sklearn.utils) and split the data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1110, 32, 20, 3)\n",
      "(1110, 11)\n"
     ]
    }
   ],
   "source": [
    "Input_dir='ziffer_sortiert_resize'\n",
    "\n",
    "files = glob.glob(Input_dir + '/*.*')\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "subdir = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"NaN\"]\n",
    "\n",
    "for aktsubdir in subdir:\n",
    "    files = glob.glob(Input_dir + '/' + aktsubdir + '/*.jpg')\n",
    "    if aktsubdir == \"NaN\":\n",
    "        category = 10                # NaN does not work --> convert to 10\n",
    "    else:\n",
    "        category = aktsubdir\n",
    "    for aktfile in files:\n",
    "        test_image = Image.open(aktfile)\n",
    "        test_image = np.array(test_image, dtype=\"float32\")\n",
    "        x_data.append(test_image)\n",
    "        y_data.append(np.array([category]))\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "y_data = to_categorical(y_data, 11)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "x_data, y_data = shuffle(x_data, y_data)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=Training_Percentage)\n",
    "else:\n",
    "    X_train = x_data\n",
    "    y_train = y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "\n",
    "The layout of the network ist a typcial CNN network with alternating **Conv2D** and **MaxPool2D** layers. Finished after **flattening** with additional **Dense** layer.\n",
    "\n",
    "#### Important\n",
    "* Shape of the input layer: (32, 20, 3)\n",
    "* Number of output layers: 11\n",
    "* As loss function \"categorical_crossentropy\" is choosen, as it is a categories task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 32, 20, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 20, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 53,719\n",
      "Trainable params: 53,713\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(32,20,3)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(11, activation = \"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The input pictures are randomly scattered for brightness, pixel shift variations and rotation angle. This is implemented with a ImageDataGenerator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "278/278 [==============================] - 5s 8ms/step - loss: 2.1557 - accuracy: 0.3606\n",
      "Epoch 2/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 1.5520 - accuracy: 0.5265\n",
      "Epoch 3/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 1.0647 - accuracy: 0.6737\n",
      "Epoch 4/500\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.9222 - accuracy: 0.7113: 0s - loss: 0.9248 - accuracy\n",
      "Epoch 5/500\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.7496 - accuracy: 0.7466\n",
      "Epoch 6/500\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.7086 - accuracy: 0.7767\n",
      "Epoch 7/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.6451 - accuracy: 0.8210\n",
      "Epoch 8/500\n",
      "278/278 [==============================] - 2s 7ms/step - loss: 0.6250 - accuracy: 0.8155\n",
      "Epoch 9/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.5337 - accuracy: 0.8377\n",
      "Epoch 10/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.4843 - accuracy: 0.8622\n",
      "Epoch 11/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.4881 - accuracy: 0.8541\n",
      "Epoch 12/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.4418 - accuracy: 0.8593\n",
      "Epoch 13/500\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.4472 - accuracy: 0.8628\n",
      "Epoch 14/500\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.3294 - accuracy: 0.9013\n",
      "Epoch 15/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.4478 - accuracy: 0.8694\n",
      "Epoch 16/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.3540 - accuracy: 0.8771\n",
      "Epoch 17/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.3787 - accuracy: 0.8646\n",
      "Epoch 18/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.3076 - accuracy: 0.9222\n",
      "Epoch 19/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2877 - accuracy: 0.9118\n",
      "Epoch 20/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.3293 - accuracy: 0.9066\n",
      "Epoch 21/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.3422 - accuracy: 0.9044\n",
      "Epoch 22/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.3228 - accuracy: 0.8837\n",
      "Epoch 23/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2534 - accuracy: 0.9275\n",
      "Epoch 24/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.3257 - accuracy: 0.9129\n",
      "Epoch 25/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.3228 - accuracy: 0.9102\n",
      "Epoch 26/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2397 - accuracy: 0.9225\n",
      "Epoch 27/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.3013 - accuracy: 0.9110\n",
      "Epoch 28/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.3059 - accuracy: 0.9174\n",
      "Epoch 29/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2457 - accuracy: 0.9103\n",
      "Epoch 30/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1933 - accuracy: 0.9379\n",
      "Epoch 31/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2202 - accuracy: 0.9165\n",
      "Epoch 32/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2299 - accuracy: 0.9331\n",
      "Epoch 33/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2536 - accuracy: 0.9277\n",
      "Epoch 34/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1913 - accuracy: 0.9280\n",
      "Epoch 35/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2364 - accuracy: 0.9287\n",
      "Epoch 36/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2499 - accuracy: 0.9209\n",
      "Epoch 37/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2151 - accuracy: 0.9367\n",
      "Epoch 38/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1976 - accuracy: 0.9466\n",
      "Epoch 39/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1543 - accuracy: 0.9619\n",
      "Epoch 40/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1857 - accuracy: 0.9392\n",
      "Epoch 41/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2585 - accuracy: 0.9313\n",
      "Epoch 42/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1983 - accuracy: 0.9552\n",
      "Epoch 43/500\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.1495 - accuracy: 0.9408\n",
      "Epoch 44/500\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.1438 - accuracy: 0.9543\n",
      "Epoch 45/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1608 - accuracy: 0.9514\n",
      "Epoch 46/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1573 - accuracy: 0.9487\n",
      "Epoch 47/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2200 - accuracy: 0.9418\n",
      "Epoch 48/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1749 - accuracy: 0.9424\n",
      "Epoch 49/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1929 - accuracy: 0.9389\n",
      "Epoch 50/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1713 - accuracy: 0.9423\n",
      "Epoch 51/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1153 - accuracy: 0.9657\n",
      "Epoch 52/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1567 - accuracy: 0.9482\n",
      "Epoch 53/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1513 - accuracy: 0.9670\n",
      "Epoch 54/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1361 - accuracy: 0.9586\n",
      "Epoch 55/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1400 - accuracy: 0.9569\n",
      "Epoch 56/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1132 - accuracy: 0.9646\n",
      "Epoch 57/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1064 - accuracy: 0.9606\n",
      "Epoch 58/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1510 - accuracy: 0.9535\n",
      "Epoch 59/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1819 - accuracy: 0.9396\n",
      "Epoch 60/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.2347 - accuracy: 0.9572\n",
      "Epoch 61/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1740 - accuracy: 0.9518: 0s - loss: 0.1744 - accuracy\n",
      "Epoch 62/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1665 - accuracy: 0.9575: 1s - loss: 0.1\n",
      "Epoch 63/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1170 - accuracy: 0.9626\n",
      "Epoch 64/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1557 - accuracy: 0.9564: 0s - loss:\n",
      "Epoch 65/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1191 - accuracy: 0.9595\n",
      "Epoch 66/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1431 - accuracy: 0.9580\n",
      "Epoch 67/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1617 - accuracy: 0.9664\n",
      "Epoch 68/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1151 - accuracy: 0.9580\n",
      "Epoch 69/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1131 - accuracy: 0.9640: 0s -\n",
      "Epoch 70/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1274 - accuracy: 0.9568\n",
      "Epoch 71/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1843 - accuracy: 0.9571\n",
      "Epoch 72/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0900 - accuracy: 0.9787\n",
      "Epoch 73/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1185 - accuracy: 0.9634\n",
      "Epoch 74/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1317 - accuracy: 0.9513\n",
      "Epoch 75/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1504 - accuracy: 0.9457: 0s - loss: 0.1\n",
      "Epoch 76/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0933 - accuracy: 0.9667\n",
      "Epoch 77/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1128 - accuracy: 0.9606: \n",
      "Epoch 78/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1385 - accuracy: 0.9630\n",
      "Epoch 79/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1950 - accuracy: 0.9467\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1155 - accuracy: 0.9651: 0s - loss: 0.116\n",
      "Epoch 81/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1373 - accuracy: 0.9637\n",
      "Epoch 82/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1549 - accuracy: 0.9539\n",
      "Epoch 83/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1103 - accuracy: 0.9641\n",
      "Epoch 84/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0780 - accuracy: 0.9731\n",
      "Epoch 85/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1070 - accuracy: 0.9737\n",
      "Epoch 86/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1055 - accuracy: 0.9652\n",
      "Epoch 87/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1525 - accuracy: 0.9688\n",
      "Epoch 88/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0893 - accuracy: 0.9699\n",
      "Epoch 89/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1112 - accuracy: 0.9632\n",
      "Epoch 90/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0698 - accuracy: 0.9773\n",
      "Epoch 91/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1243 - accuracy: 0.9640\n",
      "Epoch 92/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0812 - accuracy: 0.9801\n",
      "Epoch 93/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1511 - accuracy: 0.9679\n",
      "Epoch 94/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0921 - accuracy: 0.9748\n",
      "Epoch 95/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1630 - accuracy: 0.9624\n",
      "Epoch 96/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1124 - accuracy: 0.9677\n",
      "Epoch 97/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0957 - accuracy: 0.9705\n",
      "Epoch 98/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1158 - accuracy: 0.9653\n",
      "Epoch 99/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1093 - accuracy: 0.9694\n",
      "Epoch 100/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0661 - accuracy: 0.9774\n",
      "Epoch 101/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0914 - accuracy: 0.9664\n",
      "Epoch 102/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0947 - accuracy: 0.9783\n",
      "Epoch 103/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0948 - accuracy: 0.9731\n",
      "Epoch 104/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0851 - accuracy: 0.9711: 0s - loss: 0.0841 - accuracy: 0.97\n",
      "Epoch 105/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0780 - accuracy: 0.9712\n",
      "Epoch 106/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1123 - accuracy: 0.9652\n",
      "Epoch 107/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1284 - accuracy: 0.9632\n",
      "Epoch 108/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1215 - accuracy: 0.9523: 0s - loss: 0.1217 - accura\n",
      "Epoch 109/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0853 - accuracy: 0.9749\n",
      "Epoch 110/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1166 - accuracy: 0.9662\n",
      "Epoch 111/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0694 - accuracy: 0.9732: 0s -\n",
      "Epoch 112/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0711 - accuracy: 0.9768\n",
      "Epoch 113/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0475 - accuracy: 0.9871\n",
      "Epoch 114/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0667 - accuracy: 0.9796\n",
      "Epoch 115/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1184 - accuracy: 0.9671\n",
      "Epoch 116/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0450 - accuracy: 0.9845\n",
      "Epoch 117/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0970 - accuracy: 0.9663\n",
      "Epoch 118/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0636 - accuracy: 0.9758\n",
      "Epoch 119/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0970 - accuracy: 0.9734\n",
      "Epoch 120/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0729 - accuracy: 0.9653\n",
      "Epoch 121/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0836 - accuracy: 0.9662\n",
      "Epoch 122/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0810 - accuracy: 0.9759\n",
      "Epoch 123/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0857 - accuracy: 0.9650\n",
      "Epoch 124/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0707 - accuracy: 0.9775\n",
      "Epoch 125/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0996 - accuracy: 0.9667: 1s - loss: 0.084\n",
      "Epoch 126/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1116 - accuracy: 0.9739\n",
      "Epoch 127/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0801 - accuracy: 0.9782\n",
      "Epoch 128/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1026 - accuracy: 0.9743\n",
      "Epoch 129/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1178 - accuracy: 0.9525\n",
      "Epoch 130/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1020 - accuracy: 0.9825\n",
      "Epoch 131/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1597 - accuracy: 0.9709\n",
      "Epoch 132/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0905 - accuracy: 0.9733\n",
      "Epoch 133/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1393 - accuracy: 0.9558\n",
      "Epoch 134/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0400 - accuracy: 0.9861\n",
      "Epoch 135/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1202 - accuracy: 0.9734\n",
      "Epoch 136/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1090 - accuracy: 0.9607\n",
      "Epoch 137/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1358 - accuracy: 0.9655\n",
      "Epoch 138/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1144 - accuracy: 0.9645\n",
      "Epoch 139/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1357 - accuracy: 0.9669\n",
      "Epoch 140/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0663 - accuracy: 0.9824\n",
      "Epoch 141/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1026 - accuracy: 0.9722\n",
      "Epoch 142/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0573 - accuracy: 0.9868\n",
      "Epoch 143/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0819 - accuracy: 0.9705\n",
      "Epoch 144/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0726 - accuracy: 0.9777\n",
      "Epoch 145/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0711 - accuracy: 0.9784\n",
      "Epoch 146/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0906 - accuracy: 0.9733\n",
      "Epoch 147/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1114 - accuracy: 0.9773\n",
      "Epoch 148/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0663 - accuracy: 0.9754\n",
      "Epoch 149/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0474 - accuracy: 0.9850\n",
      "Epoch 150/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0829 - accuracy: 0.9762\n",
      "Epoch 151/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0654 - accuracy: 0.9842\n",
      "Epoch 152/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1224 - accuracy: 0.9697\n",
      "Epoch 153/500\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0467 - accuracy: 0.9809: 1s - loss: - ETA: 0s - loss: 0.0\n",
      "Epoch 154/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1117 - accuracy: 0.9657\n",
      "Epoch 155/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0720 - accuracy: 0.9776\n",
      "Epoch 156/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0634 - accuracy: 0.9819\n",
      "Epoch 157/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0825 - accuracy: 0.9804\n",
      "Epoch 158/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0527 - accuracy: 0.9860\n",
      "Epoch 159/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0891 - accuracy: 0.9763\n",
      "Epoch 160/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0695 - accuracy: 0.9817\n",
      "Epoch 161/500\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0714 - accuracy: 0.9784\n",
      "Epoch 162/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0897 - accuracy: 0.9717\n",
      "Epoch 163/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0919 - accuracy: 0.9689\n",
      "Epoch 164/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0643 - accuracy: 0.9843\n",
      "Epoch 165/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0821 - accuracy: 0.9778\n",
      "Epoch 166/500\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0858 - accuracy: 0.9793\n",
      "Epoch 167/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0292 - accuracy: 0.9915\n",
      "Epoch 168/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0735 - accuracy: 0.9749\n",
      "Epoch 169/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0684 - accuracy: 0.9807\n",
      "Epoch 170/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0677 - accuracy: 0.9798\n",
      "Epoch 171/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0314 - accuracy: 0.9877\n",
      "Epoch 172/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0544 - accuracy: 0.9896: 0s - loss: 0.054\n",
      "Epoch 173/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0656 - accuracy: 0.9825\n",
      "Epoch 174/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1073 - accuracy: 0.9816\n",
      "Epoch 175/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0766 - accuracy: 0.9868: 0s - loss: 0.0769 - accuracy: 0.\n",
      "Epoch 176/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1224 - accuracy: 0.9654\n",
      "Epoch 177/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1044 - accuracy: 0.9731: 0s - loss: 0.1045 - accu\n",
      "Epoch 178/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0519 - accuracy: 0.9873\n",
      "Epoch 179/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0589 - accuracy: 0.9782\n",
      "Epoch 180/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1071 - accuracy: 0.9749\n",
      "Epoch 181/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0383 - accuracy: 0.9821\n",
      "Epoch 182/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0521 - accuracy: 0.9780\n",
      "Epoch 183/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0868 - accuracy: 0.9757\n",
      "Epoch 184/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0777 - accuracy: 0.9776\n",
      "Epoch 185/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0860 - accuracy: 0.9736\n",
      "Epoch 186/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0573 - accuracy: 0.9799\n",
      "Epoch 187/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0923 - accuracy: 0.9742\n",
      "Epoch 188/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0666 - accuracy: 0.9836\n",
      "Epoch 189/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0670 - accuracy: 0.9752\n",
      "Epoch 190/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0767 - accuracy: 0.9857\n",
      "Epoch 191/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0322 - accuracy: 0.9897\n",
      "Epoch 192/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0468 - accuracy: 0.9890\n",
      "Epoch 193/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1186 - accuracy: 0.9654\n",
      "Epoch 194/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0674 - accuracy: 0.9780\n",
      "Epoch 195/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0719 - accuracy: 0.9729\n",
      "Epoch 196/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0691 - accuracy: 0.9764\n",
      "Epoch 197/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0616 - accuracy: 0.9787\n",
      "Epoch 198/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0471 - accuracy: 0.9817\n",
      "Epoch 199/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0615 - accuracy: 0.9732\n",
      "Epoch 200/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0541 - accuracy: 0.9763\n",
      "Epoch 201/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0496 - accuracy: 0.9833\n",
      "Epoch 202/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0642 - accuracy: 0.9871\n",
      "Epoch 203/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0699 - accuracy: 0.9768\n",
      "Epoch 204/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1060 - accuracy: 0.9856\n",
      "Epoch 205/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0326 - accuracy: 0.9930\n",
      "Epoch 206/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0884 - accuracy: 0.9797\n",
      "Epoch 207/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1336 - accuracy: 0.9754\n",
      "Epoch 208/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0554 - accuracy: 0.9867\n",
      "Epoch 209/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0684 - accuracy: 0.9792\n",
      "Epoch 210/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0523 - accuracy: 0.9861\n",
      "Epoch 211/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0579 - accuracy: 0.9851\n",
      "Epoch 212/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0584 - accuracy: 0.9834\n",
      "Epoch 213/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0366 - accuracy: 0.9905\n",
      "Epoch 214/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0657 - accuracy: 0.9853\n",
      "Epoch 215/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0288 - accuracy: 0.9882\n",
      "Epoch 216/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0352 - accuracy: 0.9889\n",
      "Epoch 217/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0660 - accuracy: 0.9841\n",
      "Epoch 218/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0652 - accuracy: 0.9810\n",
      "Epoch 219/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0569 - accuracy: 0.9861\n",
      "Epoch 220/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0731 - accuracy: 0.9819\n",
      "Epoch 221/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0582 - accuracy: 0.9829\n",
      "Epoch 222/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0604 - accuracy: 0.9838\n",
      "Epoch 223/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0578 - accuracy: 0.9779\n",
      "Epoch 224/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0452 - accuracy: 0.9843\n",
      "Epoch 225/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0434 - accuracy: 0.9836\n",
      "Epoch 226/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0810 - accuracy: 0.9762\n",
      "Epoch 227/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0460 - accuracy: 0.9854\n",
      "Epoch 228/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0285 - accuracy: 0.9918\n",
      "Epoch 229/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0565 - accuracy: 0.9867\n",
      "Epoch 230/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0712 - accuracy: 0.9823: 1s - loss: 0.1\n",
      "Epoch 231/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0811 - accuracy: 0.9783\n",
      "Epoch 232/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0392 - accuracy: 0.9923\n",
      "Epoch 233/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0448 - accuracy: 0.9874\n",
      "Epoch 234/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0620 - accuracy: 0.9843\n",
      "Epoch 235/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1067 - accuracy: 0.9797\n",
      "Epoch 236/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0415 - accuracy: 0.9876\n",
      "Epoch 237/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0842 - accuracy: 0.9836\n",
      "Epoch 238/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0290 - accuracy: 0.9911\n",
      "Epoch 239/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0753 - accuracy: 0.9797\n",
      "Epoch 240/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1063 - accuracy: 0.9824\n",
      "Epoch 241/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0715 - accuracy: 0.9857: 0s - loss: 0.0758 - \n",
      "Epoch 242/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0855 - accuracy: 0.9820\n",
      "Epoch 243/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0770 - accuracy: 0.9783\n",
      "Epoch 244/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0836 - accuracy: 0.9802\n",
      "Epoch 245/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0302 - accuracy: 0.9892\n",
      "Epoch 246/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1098 - accuracy: 0.9677\n",
      "Epoch 247/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0450 - accuracy: 0.9903: 0s - loss: 0.0450 - accuracy: \n",
      "Epoch 248/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0224 - accuracy: 0.9922\n",
      "Epoch 249/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0304 - accuracy: 0.9918\n",
      "Epoch 250/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0394 - accuracy: 0.9884\n",
      "Epoch 251/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0305 - accuracy: 0.9900\n",
      "Epoch 252/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0861 - accuracy: 0.9809\n",
      "Epoch 253/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0354 - accuracy: 0.9885\n",
      "Epoch 254/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0526 - accuracy: 0.9806\n",
      "Epoch 255/500\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0556 - accuracy: 0.98 - 2s 8ms/step - loss: 0.0556 - accuracy: 0.9808\n",
      "Epoch 256/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0421 - accuracy: 0.9868\n",
      "Epoch 257/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0523 - accuracy: 0.9854\n",
      "Epoch 258/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0379 - accuracy: 0.9868\n",
      "Epoch 259/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0548 - accuracy: 0.9816\n",
      "Epoch 260/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0411 - accuracy: 0.9919\n",
      "Epoch 261/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0273 - accuracy: 0.9913\n",
      "Epoch 262/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0337 - accuracy: 0.9887\n",
      "Epoch 263/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0625 - accuracy: 0.9822\n",
      "Epoch 264/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0487 - accuracy: 0.9887\n",
      "Epoch 265/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0480 - accuracy: 0.9842\n",
      "Epoch 266/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0608 - accuracy: 0.9854\n",
      "Epoch 267/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0393 - accuracy: 0.9867\n",
      "Epoch 268/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0353 - accuracy: 0.9925\n",
      "Epoch 269/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0684 - accuracy: 0.9811\n",
      "Epoch 270/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0721 - accuracy: 0.9767\n",
      "Epoch 271/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0321 - accuracy: 0.9898\n",
      "Epoch 272/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0663 - accuracy: 0.9791\n",
      "Epoch 273/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0677 - accuracy: 0.9837\n",
      "Epoch 274/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0403 - accuracy: 0.9885\n",
      "Epoch 275/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0669 - accuracy: 0.9752\n",
      "Epoch 276/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0530 - accuracy: 0.9841\n",
      "Epoch 277/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0540 - accuracy: 0.9810\n",
      "Epoch 278/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0172 - accuracy: 0.9962\n",
      "Epoch 279/500\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0587 - accuracy: 0.9832\n",
      "Epoch 280/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0513 - accuracy: 0.9835\n",
      "Epoch 281/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0514 - accuracy: 0.9873\n",
      "Epoch 282/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0311 - accuracy: 0.9848\n",
      "Epoch 283/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0684 - accuracy: 0.9855\n",
      "Epoch 284/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0531 - accuracy: 0.9907\n",
      "Epoch 285/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0815 - accuracy: 0.9752\n",
      "Epoch 286/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0304 - accuracy: 0.9911\n",
      "Epoch 287/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0450 - accuracy: 0.9837\n",
      "Epoch 288/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0193 - accuracy: 0.9912\n",
      "Epoch 289/500\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0580 - accuracy: 0.9803\n",
      "Epoch 290/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1387 - accuracy: 0.9715\n",
      "Epoch 291/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0501 - accuracy: 0.9803\n",
      "Epoch 292/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0990 - accuracy: 0.9829\n",
      "Epoch 293/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0471 - accuracy: 0.9879\n",
      "Epoch 294/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0287 - accuracy: 0.9933\n",
      "Epoch 295/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0210 - accuracy: 0.9927\n",
      "Epoch 296/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0508 - accuracy: 0.9837\n",
      "Epoch 297/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0270 - accuracy: 0.9903\n",
      "Epoch 298/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0870 - accuracy: 0.9901\n",
      "Epoch 299/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0570 - accuracy: 0.9867\n",
      "Epoch 300/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0414 - accuracy: 0.9846\n",
      "Epoch 301/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0538 - accuracy: 0.9865\n",
      "Epoch 302/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0346 - accuracy: 0.9903\n",
      "Epoch 303/500\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0673 - accuracy: 0.9843\n",
      "Epoch 304/500\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0382 - accuracy: 0.9879\n",
      "Epoch 305/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0860 - accuracy: 0.9829\n",
      "Epoch 306/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0502 - accuracy: 0.9861\n",
      "Epoch 307/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0728 - accuracy: 0.9812\n",
      "Epoch 308/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0374 - accuracy: 0.9860\n",
      "Epoch 309/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0357 - accuracy: 0.9864\n",
      "Epoch 310/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0452 - accuracy: 0.9857\n",
      "Epoch 311/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0682 - accuracy: 0.9826\n",
      "Epoch 312/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0205 - accuracy: 0.9947\n",
      "Epoch 313/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0532 - accuracy: 0.9865\n",
      "Epoch 314/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0432 - accuracy: 0.9862\n",
      "Epoch 315/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0508 - accuracy: 0.9774\n",
      "Epoch 316/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0509 - accuracy: 0.9870\n",
      "Epoch 317/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0442 - accuracy: 0.9873\n",
      "Epoch 318/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1058 - accuracy: 0.9747\n",
      "Epoch 319/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0396 - accuracy: 0.9892\n",
      "Epoch 320/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0566 - accuracy: 0.9819\n",
      "Epoch 321/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0485 - accuracy: 0.9828\n",
      "Epoch 322/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0883 - accuracy: 0.9753\n",
      "Epoch 323/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0178 - accuracy: 0.9936\n",
      "Epoch 324/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0238 - accuracy: 0.9924\n",
      "Epoch 325/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0370 - accuracy: 0.9871: 0s - loss: 0.0369 - accuracy: 0.98\n",
      "Epoch 326/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0513 - accuracy: 0.9889\n",
      "Epoch 327/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0285 - accuracy: 0.9879\n",
      "Epoch 328/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0665 - accuracy: 0.9804\n",
      "Epoch 329/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0847 - accuracy: 0.9770\n",
      "Epoch 330/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0256 - accuracy: 0.9911\n",
      "Epoch 331/500\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.98 - 2s 9ms/step - loss: 0.0426 - accuracy: 0.9830\n",
      "Epoch 332/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0768 - accuracy: 0.9833\n",
      "Epoch 333/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0486 - accuracy: 0.9849\n",
      "Epoch 334/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0600 - accuracy: 0.9865: 0s - loss:\n",
      "Epoch 335/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0237 - accuracy: 0.9943\n",
      "Epoch 336/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0815 - accuracy: 0.9787\n",
      "Epoch 337/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0337 - accuracy: 0.9802\n",
      "Epoch 338/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0278 - accuracy: 0.9897\n",
      "Epoch 339/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0259 - accuracy: 0.9898\n",
      "Epoch 340/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0986 - accuracy: 0.9648\n",
      "Epoch 341/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0093 - accuracy: 0.9973\n",
      "Epoch 342/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0357 - accuracy: 0.9905\n",
      "Epoch 343/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0859 - accuracy: 0.9760\n",
      "Epoch 344/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0306 - accuracy: 0.9912\n",
      "Epoch 345/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0523 - accuracy: 0.9871\n",
      "Epoch 346/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0460 - accuracy: 0.9874: 0s - loss: 0.0464 - accu\n",
      "Epoch 347/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0317 - accuracy: 0.9921\n",
      "Epoch 348/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0490 - accuracy: 0.9824\n",
      "Epoch 349/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1105 - accuracy: 0.9773\n",
      "Epoch 350/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0402 - accuracy: 0.9895\n",
      "Epoch 351/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0290 - accuracy: 0.9916\n",
      "Epoch 352/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0273 - accuracy: 0.9913\n",
      "Epoch 353/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0208 - accuracy: 0.9943\n",
      "Epoch 354/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0700 - accuracy: 0.9890\n",
      "Epoch 355/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0286 - accuracy: 0.9900\n",
      "Epoch 356/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0215 - accuracy: 0.9889\n",
      "Epoch 357/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0703 - accuracy: 0.9828\n",
      "Epoch 358/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0483 - accuracy: 0.9917\n",
      "Epoch 359/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0235 - accuracy: 0.9926\n",
      "Epoch 360/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0242 - accuracy: 0.9920\n",
      "Epoch 361/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0373 - accuracy: 0.9915\n",
      "Epoch 362/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0775 - accuracy: 0.9817\n",
      "Epoch 363/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0419 - accuracy: 0.9867\n",
      "Epoch 364/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0436 - accuracy: 0.9867\n",
      "Epoch 365/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0212 - accuracy: 0.9932\n",
      "Epoch 366/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0334 - accuracy: 0.9877: 0s - loss: 0\n",
      "Epoch 367/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1122 - accuracy: 0.9780\n",
      "Epoch 368/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0306 - accuracy: 0.9905\n",
      "Epoch 369/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0851 - accuracy: 0.9765\n",
      "Epoch 370/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0499 - accuracy: 0.9879\n",
      "Epoch 371/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0709 - accuracy: 0.9838\n",
      "Epoch 372/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0443 - accuracy: 0.9848\n",
      "Epoch 373/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0378 - accuracy: 0.9921\n",
      "Epoch 374/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0311 - accuracy: 0.9891\n",
      "Epoch 375/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1024 - accuracy: 0.9792\n",
      "Epoch 376/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0314 - accuracy: 0.9941\n",
      "Epoch 377/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0413 - accuracy: 0.9894\n",
      "Epoch 378/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0554 - accuracy: 0.9812\n",
      "Epoch 379/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0532 - accuracy: 0.9892\n",
      "Epoch 380/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0204 - accuracy: 0.9938\n",
      "Epoch 381/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0352 - accuracy: 0.9896\n",
      "Epoch 382/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0190 - accuracy: 0.9944\n",
      "Epoch 383/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0374 - accuracy: 0.9906\n",
      "Epoch 384/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0533 - accuracy: 0.9840\n",
      "Epoch 385/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0337 - accuracy: 0.9897\n",
      "Epoch 386/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0245 - accuracy: 0.9903\n",
      "Epoch 387/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0559 - accuracy: 0.9894\n",
      "Epoch 388/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0621 - accuracy: 0.9800\n",
      "Epoch 389/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0382 - accuracy: 0.9873\n",
      "Epoch 390/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0165 - accuracy: 0.9965\n",
      "Epoch 391/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0426 - accuracy: 0.9913\n",
      "Epoch 392/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0532 - accuracy: 0.9858\n",
      "Epoch 393/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0255 - accuracy: 0.9900\n",
      "Epoch 394/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0340 - accuracy: 0.9875\n",
      "Epoch 395/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0333 - accuracy: 0.9903\n",
      "Epoch 396/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0252 - accuracy: 0.9950\n",
      "Epoch 397/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0732 - accuracy: 0.9814: 1s - loss: 0.0916  - ETA: 0s - los\n",
      "Epoch 398/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0194 - accuracy: 0.9963\n",
      "Epoch 399/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1041 - accuracy: 0.9829: 0s - loss: 0.1092 - accuracy: \n",
      "Epoch 400/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0376 - accuracy: 0.9863\n",
      "Epoch 401/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0355 - accuracy: 0.9864\n",
      "Epoch 402/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0515 - accuracy: 0.9809\n",
      "Epoch 403/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0682 - accuracy: 0.9830\n",
      "Epoch 404/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0375 - accuracy: 0.9897: 0s - loss: 0.038\n",
      "Epoch 405/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0177 - accuracy: 0.9968\n",
      "Epoch 406/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0487 - accuracy: 0.9764\n",
      "Epoch 407/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0228 - accuracy: 0.9908\n",
      "Epoch 408/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0159 - accuracy: 0.9934\n",
      "Epoch 409/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0386 - accuracy: 0.9895: 0s\n",
      "Epoch 410/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0313 - accuracy: 0.9954: 0s - loss: 0.0314 - accuracy: \n",
      "Epoch 411/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0274 - accuracy: 0.9912\n",
      "Epoch 412/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0755 - accuracy: 0.9864\n",
      "Epoch 413/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0239 - accuracy: 0.9932\n",
      "Epoch 414/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0504 - accuracy: 0.9871\n",
      "Epoch 415/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0598 - accuracy: 0.9857\n",
      "Epoch 416/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0591 - accuracy: 0.9841\n",
      "Epoch 417/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0449 - accuracy: 0.9881: 0s - loss: 0.0\n",
      "Epoch 418/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0309 - accuracy: 0.9898\n",
      "Epoch 419/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0255 - accuracy: 0.9917\n",
      "Epoch 420/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0269 - accuracy: 0.9913\n",
      "Epoch 421/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0452 - accuracy: 0.9893\n",
      "Epoch 422/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0176 - accuracy: 0.9938\n",
      "Epoch 423/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0272 - accuracy: 0.9948\n",
      "Epoch 424/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0361 - accuracy: 0.9876\n",
      "Epoch 425/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0305 - accuracy: 0.9942\n",
      "Epoch 426/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0551 - accuracy: 0.9843\n",
      "Epoch 427/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0138 - accuracy: 0.9964\n",
      "Epoch 428/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0396 - accuracy: 0.9884\n",
      "Epoch 429/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0384 - accuracy: 0.9879\n",
      "Epoch 430/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0692 - accuracy: 0.9833\n",
      "Epoch 431/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0230 - accuracy: 0.9946\n",
      "Epoch 432/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0514 - accuracy: 0.9878\n",
      "Epoch 433/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0210 - accuracy: 0.9922: 0s - loss: 0.0207 - accuracy: 0.99\n",
      "Epoch 434/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0447 - accuracy: 0.9842\n",
      "Epoch 435/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0158 - accuracy: 0.9976\n",
      "Epoch 436/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0506 - accuracy: 0.9877\n",
      "Epoch 437/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0373 - accuracy: 0.9913\n",
      "Epoch 438/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0237 - accuracy: 0.9913\n",
      "Epoch 439/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0554 - accuracy: 0.9843\n",
      "Epoch 440/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0332 - accuracy: 0.9902\n",
      "Epoch 441/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0326 - accuracy: 0.9906\n",
      "Epoch 442/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0251 - accuracy: 0.9941\n",
      "Epoch 443/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0324 - accuracy: 0.9906\n",
      "Epoch 444/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0241 - accuracy: 0.9908\n",
      "Epoch 445/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0150 - accuracy: 0.9934\n",
      "Epoch 446/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0200 - accuracy: 0.9945\n",
      "Epoch 447/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0214 - accuracy: 0.9908\n",
      "Epoch 448/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0295 - accuracy: 0.9882\n",
      "Epoch 449/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0407 - accuracy: 0.9840\n",
      "Epoch 450/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0290 - accuracy: 0.9879\n",
      "Epoch 451/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0416 - accuracy: 0.9842\n",
      "Epoch 452/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0169 - accuracy: 0.9957\n",
      "Epoch 453/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0261 - accuracy: 0.9936\n",
      "Epoch 454/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0217 - accuracy: 0.9899\n",
      "Epoch 455/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0760 - accuracy: 0.9925\n",
      "Epoch 456/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0619 - accuracy: 0.9918\n",
      "Epoch 457/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0192 - accuracy: 0.9950\n",
      "Epoch 458/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0209 - accuracy: 0.9944\n",
      "Epoch 459/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0321 - accuracy: 0.9933\n",
      "Epoch 460/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0520 - accuracy: 0.9878\n",
      "Epoch 461/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0284 - accuracy: 0.9928\n",
      "Epoch 462/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0267 - accuracy: 0.9927\n",
      "Epoch 463/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0345 - accuracy: 0.9945\n",
      "Epoch 464/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0681 - accuracy: 0.9841\n",
      "Epoch 465/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0570 - accuracy: 0.9871\n",
      "Epoch 466/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0336 - accuracy: 0.9889\n",
      "Epoch 467/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0528 - accuracy: 0.9903\n",
      "Epoch 468/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0884 - accuracy: 0.9866\n",
      "Epoch 469/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0182 - accuracy: 0.9892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0556 - accuracy: 0.9841\n",
      "Epoch 471/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.1022 - accuracy: 0.9804\n",
      "Epoch 472/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0274 - accuracy: 0.9938\n",
      "Epoch 473/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0334 - accuracy: 0.9924\n",
      "Epoch 474/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0296 - accuracy: 0.9925\n",
      "Epoch 475/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0284 - accuracy: 0.9940\n",
      "Epoch 476/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0404 - accuracy: 0.9945\n",
      "Epoch 477/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0227 - accuracy: 0.9955\n",
      "Epoch 478/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0278 - accuracy: 0.9911\n",
      "Epoch 479/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0454 - accuracy: 0.9910\n",
      "Epoch 480/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0290 - accuracy: 0.9900\n",
      "Epoch 481/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0434 - accuracy: 0.9914\n",
      "Epoch 482/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0689 - accuracy: 0.9823\n",
      "Epoch 483/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0565 - accuracy: 0.9801\n",
      "Epoch 484/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0184 - accuracy: 0.9928\n",
      "Epoch 485/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0219 - accuracy: 0.9925\n",
      "Epoch 486/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0394 - accuracy: 0.9895\n",
      "Epoch 487/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0279 - accuracy: 0.9939: 0s - loss: 0.0226 \n",
      "Epoch 488/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0261 - accuracy: 0.9925\n",
      "Epoch 489/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0112 - accuracy: 0.9973\n",
      "Epoch 490/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0153 - accuracy: 0.9897\n",
      "Epoch 491/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0608 - accuracy: 0.9863\n",
      "Epoch 492/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0129 - accuracy: 0.9953\n",
      "Epoch 493/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0341 - accuracy: 0.9920\n",
      "Epoch 494/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0402 - accuracy: 0.9937\n",
      "Epoch 495/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0566 - accuracy: 0.9840\n",
      "Epoch 496/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0271 - accuracy: 0.9958\n",
      "Epoch 497/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0465 - accuracy: 0.9897\n",
      "Epoch 498/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0476 - accuracy: 0.9877\n",
      "Epoch 499/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0143 - accuracy: 0.9977\n",
      "Epoch 500/500\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0426 - accuracy: 0.9869\n"
     ]
    }
   ],
   "source": [
    "Batch_Size = 4\n",
    "Shift_Range = 1\n",
    "Brightness_Range = 0.3\n",
    "Rotation_Angle = 10\n",
    "ZoomRange = 0.4\n",
    "\n",
    "datagen = ImageDataGenerator(width_shift_range=[-Shift_Range,Shift_Range], \n",
    "                             height_shift_range=[-Shift_Range,Shift_Range],\n",
    "                             brightness_range=[1-Brightness_Range,1+Brightness_Range],\n",
    "                             zoom_range=[1-ZoomRange, 1+ZoomRange],\n",
    "                             rotation_range=Rotation_Angle)\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    validation_iterator = datagen.flow(X_test, y_test, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, validation_data = validation_iterator, epochs = Epoch_Anz)\n",
    "else:\n",
    "    train_iterator = datagen.flow(x_data, y_data, batch_size=Batch_Size)\n",
    "    history = model.fit(train_iterator, epochs = Epoch_Anz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learing result\n",
    " \n",
    "* Visualization of the training and validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_ges = np.append(loss_ges, history.history['loss'])\n",
    "plt.semilogy(history.history['loss'])\n",
    "\n",
    "if (Training_Percentage > 0):\n",
    "    val_loss_ges = np.append(val_loss_ges, history.history['val_loss'])\n",
    "    plt.semilogy(history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','eval'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model by hand\n",
    "\n",
    "* The following code uses the trained model to check the deviation for each picture.\n",
    "* x-axis walks through each pixel, y-axis shows the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Input_dir='ziffer_sortiert_resize'\n",
    "subdir = [\"NaN\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "res = []\n",
    "\n",
    "for aktsubdir in subdir:\n",
    "    files = glob.glob(Input_dir + '/' + aktsubdir + '\\*.jpg')\n",
    "    if aktsubdir == \"NaN\":\n",
    "        zw1 = -1\n",
    "    else:\n",
    "        zw1 = int(aktsubdir)\n",
    "    for aktfile in files:\n",
    "        test_image = Image.open(aktfile)\n",
    "        test_image = np.array(test_image, dtype=\"float32\")\n",
    "        img = np.reshape(test_image,[1,32,20,3])\n",
    "        classes = np.argmax(model.predict(img), axis=-1)\n",
    "        classes = classes[0]\n",
    "        if classes == 10: \n",
    "            classes = -1\n",
    "        zw2 = classes\n",
    "        zw3 = zw2 - zw1\n",
    "        res.append(np.array([zw1, zw2, zw3]))\n",
    "\n",
    "res = np.asarray(res)\n",
    "\n",
    "\n",
    "plt.plot(res[:,0])\n",
    "plt.plot(res[:,1])\n",
    "plt.title('Result')\n",
    "plt.ylabel('Digital Value')\n",
    "plt.xlabel('#Picture')\n",
    "plt.legend(['real','model'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "\n",
    "* Save the model to the file with the \"h5\" file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Muell\\AppData\\Local\\Temp\\tmpwqpjqf8y\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "219388"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileName = TFliteNamingAndVersion\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Muell\\AppData\\Local\\Temp\\tmpsmzbd85u\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Muell\\AppData\\Local\\Temp\\tmpsmzbd85u\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63824"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileName = TFliteNamingAndVersion + \"q\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def representative_dataset():\n",
    "    for _ in range(500):\n",
    "      data = np.random.rand(1, 32, 20, 3) * 255\n",
    "      yield [data.astype(np.float32)]\n",
    "        \n",
    "converter2 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter2.representative_dataset = representative_dataset\n",
    "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter2.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter2.convert()\n",
    "\n",
    "open(FileName + \".tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check each image for expected and deviation\n",
    "* setting the switch \"only_deviation = true\" will only print the images for which the classification and the CNN-result deviates\n",
    "\n",
    "The output contains the following information:\n",
    "\n",
    "| Filename      | Expected Category           | Predicted Category        |\n",
    "|------------- |:-----------------------------:|--------------|\n",
    "| ziffer_sortiert_resize_NaN/5\\Ziffer_4_0034.jpg | 4  | -1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ziffer_sortiert_resize/7\\D7_2020-08-20_15-23-28.jpg 7 1\n"
     ]
    }
   ],
   "source": [
    "Input_dir='ziffer_sortiert_resize'\n",
    "only_deviation = True\n",
    "\n",
    "subdir = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"NaN\"]\n",
    "\n",
    "for aktsubdir in subdir:\n",
    "    files = glob.glob(Input_dir + '/' + aktsubdir + '\\*.jpg')\n",
    "    expected_class = aktsubdir\n",
    "    for aktfile in files:\n",
    "        test_image = Image.open(aktfile)\n",
    "        test_image = np.array(test_image, dtype=\"float32\")\n",
    "        img = np.reshape(test_image,[1,32,20,3])\n",
    "        classes = np.argmax(model.predict(img), axis=-1)\n",
    "        classes = classes[0]\n",
    "        if classes == 10: \n",
    "            classes = \"NaN\"\n",
    "        if only_deviation == True:\n",
    "            if str(classes) != str(expected_class):\n",
    "                print(aktfile + \" \" + aktsubdir +  \" \" + str(classes))\n",
    "        else:\n",
    "            print(aktfile + \" \" + aktsubdir +  \" \" + str(classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the images shows, that this are border line images, which can be interpreted as a good digit or a faulty one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
